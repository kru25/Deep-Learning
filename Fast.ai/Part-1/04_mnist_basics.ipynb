{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello everyone,so in last chapter we discussed about an end to end process on building an Image\n",
    "Classifier Application which included data collection,data cleaning,building a model and then using\n",
    "that model to clean our data.We also learnt on saving our model and how to turn it into an application\n",
    "using voila.We also went through the risks associated with a deep learning project and how they can \n",
    "be avoided before deploying the model.\n",
    "In this chapter,we are going to discuss about training a digit classifier using baseline model,we\n",
    "will also learn about different operations on tensors and arrays in Pytorch,how to train a neural net\n",
    "work from scratch and some fundamentals of Neural net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under the Hood: Training a Digit Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw previously about end to end project on deep learning.Now in this chapter we would explore more\n",
    "on computer vision and its basic concepts and tools for deep learning.\n",
    "We will also learn about tensors and arrays and how different operations are performed on them by \n",
    "broadcasting.We will discuss about basic terms such as gradient,loss function,updating weights,\n",
    "mini-batches,optimizer etc and how we can build them using scratch and how we put them together.\n",
    "In further chapters,we would learn more about specific examples.But this chapter would teach concepts\n",
    "of a basic neural network which is same for every deep learning application.So this chapter will lay\n",
    "foundations for every deep learning project we do in future.Here we will be mainly focusing on \n",
    "computer vision applications.\n",
    "Very first step towards it is how do we represent image..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixels: The Foundations of Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we trained many Image Classifiers where input are Images.But we also know this fact that \n",
    "all ML and Deep learning algorithms accept only numerical data as input.So how do we convert images to\n",
    "numbers so that our models can accept it.To understand this we will be using the famous MNIST dataset\n",
    "which consists of Images of handwritten digits,collected by Yann Lecun.Lecun used it to develop a\n",
    "digit classifier system in 1998.He used lenet-5 architecture for the model.It is considered a very\n",
    "important benchmark in the history of Deep learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sidebar: Tenacity and Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen in the first Chapter about the history of neural networks and deep learning.Initial \n",
    "neural nets were simple and therefore did not give pathbreaking results.They were also very hyped back\n",
    "then.By 1990s and 2000s , they had lost all popularity and a handful of researchers were working on\n",
    "it.Geoffery Hinton, termed as \"Father of Deep learning\" along with 2 other researchers won the famous\n",
    "\"Turing Award\" in 2018 for his works in Machine Learning and Deep learning during the time when no one\n",
    "took interest in it and today we know its ruling the world.\n",
    "Most of his initial works were rejected and not recognized by scientific community just because they \n",
    "used neural networks.The digit classification using neural network which we will be studying in this \n",
    "chapter was also published till then but was not well accepted by researchers.Its surprising that it \n",
    "became an official method for recognizing checks during that time in US!!!.\n",
    "The Deep learning algorithms we study today is the result of years of hardwork by many researchers.\n",
    "Works such as long-short memory architectures(LSTM) and backpropogation for neural networks were \n",
    "ignored for decades but today they make foundations of the AI works going on WorldWide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get to learn a lot of things from these researchers who worked so hard to give world such wonderful\n",
    "and useful innovations.While learning deep learning we would face many difficulties and obviously we \n",
    "would fail.But we would keep trying with different models,different parameters and eventually we would\n",
    "succeed.So let us start with this Chapter!!!-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End sidebar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as we mentioned we would be working on the MNIST dataset consisting of images of hand written \n",
    "digits.For the ease here we are considering images of 3 and 7 only.So let us download a sample of this\n",
    "dataset containing images of these digits.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#untar_data to download the path and decompress the images\n",
    "path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide BASE_PATH attribute to identify root path\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what is inside the directory using ls method provided by fastai.It returns the object of\n",
    "class L(like list).It provides the count of items and also the names of the items in the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pathlib.WindowsPath"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(path)#pathlib path object Part of Python Standard library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-9afc40ab5db7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-9afc40ab5db7>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    path.ls? #ls-part of fastcore library(Foundations from fast.ai)\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "path.ls? #ls-part of fastcore library(Foundations from fast.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('labels.csv'),Path('train'),Path('valid')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Folders present in the path/downloaded dataset\n",
    "path.ls()\n",
    "#Using ls method we see the list of directories or folders in the path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our sample dataset consists of three files:training set,validation set and a labels file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('train/3'),Path('train/7')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shows the contents of train set\n",
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned earlier we will be using images of 3s and 7s so our training set consists of two \n",
    "folders containing images of 3 and 7s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6131) [Path('train/3/10.png'),Path('train/3/10000.png'),Path('train/3/10011.png'),Path('train/3/10031.png'),Path('train/3/10034.png'),Path('train/3/10042.png'),Path('train/3/10052.png'),Path('train/3/1007.png'),Path('train/3/10074.png'),Path('train/3/10091.png')...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Storing the images sorted in different variables\n",
    "threes = (path/'train'/'3').ls().sorted()#Contains sorted contents of 3\n",
    "sevens = (path/'train'/'7').ls().sorted()#Contains sorted contents of 7\n",
    "threes\n",
    "#We saw the contents of the 3 and 7 folders in training set and all of them are images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we display one of the images in the 3s dataset using the path.We used PIL(Python Imaging Library)\n",
    "to store the image and display the image.We use Image class from PIL,it is the most common Python\n",
    "Package for working with Images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9ElEQVR4nM3Or0sDcRjH8c/pgrfBVBjCgibThiKIyTWbWF1bORhGwxARxH/AbtW0JoIGwzXRYhJhtuFY2q1ocLgbe3sGReTuuWbwkx6+r+/zQ/pncX6q+YOldSe6nG3dn8U/rTQ70L8FCGJUewvxl7NTmezNb8xIkvKugr1HSeMP6SrWOVkoTEuSyh0Gm2n3hQyObMnXnxkempRrvgD+gokzwxFAr7U7YXHZ8x4A/Dl7rbu6D2yl3etcw/F3nZgfRVI7rXM7hMUUqzzBec427x26rkmlkzEEa4nnRqnSOH2F0UUx0ePzlbuqMXAHgN6GY9if5xP8dmtHFfwjuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x206596EEC70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3_path = threes[1] #storing the path for one image in threes variable\n",
    "im3 = Image.open(im3_path) #displays the image of the digit PIL=Python Imaging Library\n",
    "im3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we had discussed earlier that we cannot pass images in \"jpg/png\" format directly through the ML or\n",
    "Deep learning algorithms , we can only pass numbers.So how do we get Images in number format!!.\n",
    "We very well know that computer saves everything in form of numbers so it also views images as nos.It\n",
    "To view the numbers which form an image we convert it into a Numpy Array or Pytorch Tensor.Both have\n",
    " same properties except the fact that numpy arrays work well on CPU while tensors are particularly \n",
    "used in GPU.So let us convert a part of image into array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,  29],\n",
       "       [  0,   0,   0,  48, 166, 224],\n",
       "       [  0,  93, 244, 249, 253, 187],\n",
       "       [  0, 107, 253, 253, 230,  48],\n",
       "       [  0,   3,  20,  20,  15,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Passing image onto array so as to get the pixels or features\n",
    "array(im3)[4:10,4:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indexing [4:10,4:10] indicates the features from 4th row(including) till 10th row(excluded).And \n",
    "the same is applied for columns.The first index refers to rows and second refers to columns.Row \n",
    "indexes from top to bottom and column from left to right...Pytorch Tensors also follow the same format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,  29],\n",
       "        [  0,   0,   0,  48, 166, 224],\n",
       "        [  0,  93, 244, 249, 253, 187],\n",
       "        [  0, 107, 253, 253, 230,  48],\n",
       "        [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#passing image onto a tensor so as to get the pixels or features\n",
    "#tensor is similar to arrays just that they have more functionality and the computations are faster \n",
    "#and easier and can be done on GPU\n",
    "tensor(im3)[4:10,4:10]#passing image through tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are using tensors to pick up the pixels(numerical features) in the image and then we slice a \n",
    "part and pass the same through DataFrame.DataFrame is again one of the most widely used Pandas object\n",
    "used for data processing and manipulation.Here we use it to color code the values using gradient.\n",
    "Dataframe has this functionality and this shows how images are created using pixel values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values are coded in a gradient from white to black.Since the pixel values range from 0 to 255,so \n",
    "0 represents white and then with pixel value increase the color becomes dark so 255 represents dark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col0,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col1,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col2,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col3,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col4,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col5,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col6,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col7,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col8,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col9,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col10,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col11,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col12,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col13,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col14,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col15,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col16,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col17,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col0,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col1,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col2,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col3,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col4,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col15,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col16,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col17,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col0,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col1,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col2,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col15,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col16,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col17,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col0,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col15,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col16,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col17,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col0,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col6,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col7,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col8,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col9,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col10,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col15,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col16,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col17,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col0,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col5,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col6,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col7,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col8,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col9,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col15,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col16,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col17,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col0,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col1,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col2,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col3,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col4,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col5,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col6,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col7,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col8,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col9,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col14,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col15,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col16,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col17,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col0,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col1,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col2,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col3,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col4,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col5,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col6,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col13,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col14,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col15,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col16,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col17,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col0,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col1,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col2,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col3,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col4,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col13,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col14,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col15,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col16,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col17,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col0,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col1,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col2,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col3,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col4,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col16,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col17,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col0,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col1,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col2,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col3,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col4,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col5,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col6,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col17{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #ffffff;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col5{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #efefef;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col6,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col13{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #7c7c7c;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col7{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #4a4a4a;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col8,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col9,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col10,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col5,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col6,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col7,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col11,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col12,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col13,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col4,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col12,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col13,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col1,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col2,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col3,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col12,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col13,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col12,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col11,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col11,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col11,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col12,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col13,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col14,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col15,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col16{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #000000;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col11{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #606060;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col12{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #4d4d4d;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col14{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #bbbbbb;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col3{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #e4e4e4;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col4,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col6{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #6b6b6b;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col8,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col14,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col14{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #171717;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col9,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col11{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #4b4b4b;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col10,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col10,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col8,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col10,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col8,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col10{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #010101;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col1{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #272727;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col2{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #0a0a0a;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col3{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #050505;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col5{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #333333;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col6{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #e6e6e6;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col7,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col10{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #fafafa;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col8{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #fbfbfb;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col9{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #fdfdfd;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col4{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #1b1b1b;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col5{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #e0e0e0;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col11{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #4e4e4e;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col14{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #767676;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col1{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #fcfcfc;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col2,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col3{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #f6f6f6;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col4,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col7{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #f8f8f8;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col10,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col7{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #e8e8e8;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col11{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #222222;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col13,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col12{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #090909;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col14{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #d0d0d0;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col10,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col11,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col6{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #060606;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col13{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #979797;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col8{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #b6b6b6;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col9{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #252525;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col12{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #999999;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col5{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #f9f9f9;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col7{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #101010;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col9,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col9{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #020202;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col11{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #545454;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col12{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #f1f1f1;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col5{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #f7f7f7;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col7{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #030303;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col12{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #181818;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col13{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #303030;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col14{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #a9a9a9;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col15{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #fefefe;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col8,#T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col9{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #bababa;\n",
       "            color:  #000000;\n",
       "        }#T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col10{\n",
       "            font-size:  6pt;\n",
       "            background-color:  #393939;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>        <th class=\"col_heading level0 col1\" >1</th>        <th class=\"col_heading level0 col2\" >2</th>        <th class=\"col_heading level0 col3\" >3</th>        <th class=\"col_heading level0 col4\" >4</th>        <th class=\"col_heading level0 col5\" >5</th>        <th class=\"col_heading level0 col6\" >6</th>        <th class=\"col_heading level0 col7\" >7</th>        <th class=\"col_heading level0 col8\" >8</th>        <th class=\"col_heading level0 col9\" >9</th>        <th class=\"col_heading level0 col10\" >10</th>        <th class=\"col_heading level0 col11\" >11</th>        <th class=\"col_heading level0 col12\" >12</th>        <th class=\"col_heading level0 col13\" >13</th>        <th class=\"col_heading level0 col14\" >14</th>        <th class=\"col_heading level0 col15\" >15</th>        <th class=\"col_heading level0 col16\" >16</th>        <th class=\"col_heading level0 col17\" >17</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col7\" class=\"data row0 col7\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col8\" class=\"data row0 col8\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col9\" class=\"data row0 col9\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col10\" class=\"data row0 col10\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col11\" class=\"data row0 col11\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col12\" class=\"data row0 col12\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col13\" class=\"data row0 col13\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col14\" class=\"data row0 col14\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col15\" class=\"data row0 col15\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col16\" class=\"data row0 col16\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row0_col17\" class=\"data row0 col17\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col5\" class=\"data row1 col5\" >29</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col6\" class=\"data row1 col6\" >150</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col7\" class=\"data row1 col7\" >195</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col8\" class=\"data row1 col8\" >254</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col9\" class=\"data row1 col9\" >255</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col10\" class=\"data row1 col10\" >254</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col11\" class=\"data row1 col11\" >176</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col12\" class=\"data row1 col12\" >193</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col13\" class=\"data row1 col13\" >150</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col14\" class=\"data row1 col14\" >96</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col15\" class=\"data row1 col15\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col16\" class=\"data row1 col16\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row1_col17\" class=\"data row1 col17\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col3\" class=\"data row2 col3\" >48</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col4\" class=\"data row2 col4\" >166</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col5\" class=\"data row2 col5\" >224</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col6\" class=\"data row2 col6\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col7\" class=\"data row2 col7\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col8\" class=\"data row2 col8\" >234</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col9\" class=\"data row2 col9\" >196</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col10\" class=\"data row2 col10\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col11\" class=\"data row2 col11\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col12\" class=\"data row2 col12\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col13\" class=\"data row2 col13\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col14\" class=\"data row2 col14\" >233</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col15\" class=\"data row2 col15\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col16\" class=\"data row2 col16\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row2_col17\" class=\"data row2 col17\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col0\" class=\"data row3 col0\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col1\" class=\"data row3 col1\" >93</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col2\" class=\"data row3 col2\" >244</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col3\" class=\"data row3 col3\" >249</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col4\" class=\"data row3 col4\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col5\" class=\"data row3 col5\" >187</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col6\" class=\"data row3 col6\" >46</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col7\" class=\"data row3 col7\" >10</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col8\" class=\"data row3 col8\" >8</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col9\" class=\"data row3 col9\" >4</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col10\" class=\"data row3 col10\" >10</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col11\" class=\"data row3 col11\" >194</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col12\" class=\"data row3 col12\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col13\" class=\"data row3 col13\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col14\" class=\"data row3 col14\" >233</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col15\" class=\"data row3 col15\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col16\" class=\"data row3 col16\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row3_col17\" class=\"data row3 col17\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col0\" class=\"data row4 col0\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col1\" class=\"data row4 col1\" >107</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col2\" class=\"data row4 col2\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col3\" class=\"data row4 col3\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col4\" class=\"data row4 col4\" >230</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col5\" class=\"data row4 col5\" >48</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col6\" class=\"data row4 col6\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col7\" class=\"data row4 col7\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col8\" class=\"data row4 col8\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col9\" class=\"data row4 col9\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col10\" class=\"data row4 col10\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col11\" class=\"data row4 col11\" >192</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col12\" class=\"data row4 col12\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col13\" class=\"data row4 col13\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col14\" class=\"data row4 col14\" >156</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col15\" class=\"data row4 col15\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col16\" class=\"data row4 col16\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row4_col17\" class=\"data row4 col17\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col0\" class=\"data row5 col0\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col1\" class=\"data row5 col1\" >3</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col2\" class=\"data row5 col2\" >20</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col3\" class=\"data row5 col3\" >20</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col4\" class=\"data row5 col4\" >15</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col5\" class=\"data row5 col5\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col6\" class=\"data row5 col6\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col7\" class=\"data row5 col7\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col8\" class=\"data row5 col8\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col9\" class=\"data row5 col9\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col10\" class=\"data row5 col10\" >43</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col11\" class=\"data row5 col11\" >224</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col12\" class=\"data row5 col12\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col13\" class=\"data row5 col13\" >245</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col14\" class=\"data row5 col14\" >74</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col15\" class=\"data row5 col15\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col16\" class=\"data row5 col16\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row5_col17\" class=\"data row5 col17\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col0\" class=\"data row6 col0\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col1\" class=\"data row6 col1\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col3\" class=\"data row6 col3\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col4\" class=\"data row6 col4\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col5\" class=\"data row6 col5\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col6\" class=\"data row6 col6\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col7\" class=\"data row6 col7\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col8\" class=\"data row6 col8\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col9\" class=\"data row6 col9\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col10\" class=\"data row6 col10\" >249</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col11\" class=\"data row6 col11\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col12\" class=\"data row6 col12\" >245</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col13\" class=\"data row6 col13\" >126</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col14\" class=\"data row6 col14\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col15\" class=\"data row6 col15\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col16\" class=\"data row6 col16\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row6_col17\" class=\"data row6 col17\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col0\" class=\"data row7 col0\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col1\" class=\"data row7 col1\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col2\" class=\"data row7 col2\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col3\" class=\"data row7 col3\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col4\" class=\"data row7 col4\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col5\" class=\"data row7 col5\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col6\" class=\"data row7 col6\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col7\" class=\"data row7 col7\" >14</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col8\" class=\"data row7 col8\" >101</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col9\" class=\"data row7 col9\" >223</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col10\" class=\"data row7 col10\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col11\" class=\"data row7 col11\" >248</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col12\" class=\"data row7 col12\" >124</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col13\" class=\"data row7 col13\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col14\" class=\"data row7 col14\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col15\" class=\"data row7 col15\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col16\" class=\"data row7 col16\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row7_col17\" class=\"data row7 col17\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col0\" class=\"data row8 col0\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col1\" class=\"data row8 col1\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col2\" class=\"data row8 col2\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col3\" class=\"data row8 col3\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col4\" class=\"data row8 col4\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col5\" class=\"data row8 col5\" >11</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col6\" class=\"data row8 col6\" >166</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col7\" class=\"data row8 col7\" >239</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col8\" class=\"data row8 col8\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col9\" class=\"data row8 col9\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col10\" class=\"data row8 col10\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col11\" class=\"data row8 col11\" >187</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col12\" class=\"data row8 col12\" >30</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col13\" class=\"data row8 col13\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col14\" class=\"data row8 col14\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col15\" class=\"data row8 col15\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col16\" class=\"data row8 col16\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row8_col17\" class=\"data row8 col17\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col0\" class=\"data row9 col0\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col1\" class=\"data row9 col1\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col2\" class=\"data row9 col2\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col3\" class=\"data row9 col3\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col4\" class=\"data row9 col4\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col5\" class=\"data row9 col5\" >16</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col6\" class=\"data row9 col6\" >248</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col7\" class=\"data row9 col7\" >250</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col8\" class=\"data row9 col8\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col9\" class=\"data row9 col9\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col10\" class=\"data row9 col10\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col11\" class=\"data row9 col11\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col12\" class=\"data row9 col12\" >232</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col13\" class=\"data row9 col13\" >213</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col14\" class=\"data row9 col14\" >111</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col15\" class=\"data row9 col15\" >2</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col16\" class=\"data row9 col16\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row9_col17\" class=\"data row9 col17\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col0\" class=\"data row10 col0\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col1\" class=\"data row10 col1\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col2\" class=\"data row10 col2\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col3\" class=\"data row10 col3\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col4\" class=\"data row10 col4\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col5\" class=\"data row10 col5\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col6\" class=\"data row10 col6\" >0</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col7\" class=\"data row10 col7\" >43</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col8\" class=\"data row10 col8\" >98</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col9\" class=\"data row10 col9\" >98</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col10\" class=\"data row10 col10\" >208</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col11\" class=\"data row10 col11\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col12\" class=\"data row10 col12\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col13\" class=\"data row10 col13\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col14\" class=\"data row10 col14\" >253</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col15\" class=\"data row10 col15\" >187</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col16\" class=\"data row10 col16\" >22</td>\n",
       "                        <td id=\"T_689745b7_23e2_11eb_a8ec_afdbc3122090row10_col17\" class=\"data row10 col17\" >0</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x206596e2f70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3_t = tensor(im3)#Image to tensor\n",
    "df = pd.DataFrame(im3_t[4:15,4:22])#converting it into DataFrame to get gradients\n",
    "df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')#Shows background gradient \n",
    "#for the Dataframe(0-White,255-Black)\n",
    "#Here a part of image is only shown since we have sliced the tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire image consists of 28 pixels in rows and 28 pixels in columns.So in total 784 pixels are \n",
    "there.Above we displayed 11*18 pixels.(This image is very small than the ones we take in phones which\n",
    "has millions of pixels.)As we have seen how images can be represented in arrays or tensors we can now\n",
    "build a model to identify 3s and 7s from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving forward we should think about since now we have tensors representing our images,what \n",
    "features are important for distinguishing between 3s and 7s and how can we identify them???..We need \n",
    "not think about something complicated instead of some central value which can represent group of 3s or\n",
    "7s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Try: Pixel Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now before moving forward with deep learning we would try something simple and see what results we \n",
    "obtain.So the first approach can be finding the average value of all the pixels for 3s and for 7s\n",
    "separately which would be the central measure representing 3 and 7.Then for identifying any image as a\n",
    "3 or 7 we observe which image has the pixel value close to the 3s or 7s value.This is certainly a very\n",
    "basic approach but it can make a good baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So,first we have to get mean of the pixel values for each image in both the groups.We would learn some\n",
    "basic tensor and array operations in this.We create a list of tensors using Python list comprehension\n",
    "containing the tensor objects of all the images in sevens and threes.\"tensor(Image.open(o))\" is used \n",
    "for converting the image to tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, 6265)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Baseline model\n",
    "seven_tensors = [tensor(Image.open(o)) for o in sevens] #List of tensors of all 7s(list comprehension)\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]#list of tensors of all 3s\n",
    "len(three_tensors),len(seven_tensors)#length of list containing 3s and 7s as tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now converted images into tensors so we use fastai's \"show_image\" to display the image by \n",
    "passing tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAJHElEQVR4nO2bXXMSZxuAL1jYXYQsiCYxIWIIjImJ0TaVTu2H41FnnGmPPOtMf0NP+i/6H9oDx+OOOtMjW6cdGz/Sk1ZqxkRDhCTQEAjfsLDsvgeWbbMmxgrEzDtcR5ln+bi5eJ5n7/t+iM0wDPr8g/1tB3DY6Aux0BdioS/EQl+IBcc+1/+fb0G23Qb7M8RCX4iFvhALfSEW+kIs9IVY6Aux0BdiYb/ErGMMw6DVatFsNqlUKmiaRrPZpNls0mg0Xnq8LMtIkoSu6+i6jtPpxOFw4HQ6EQQBWZZxOHoXds+FaJpGvV4nHo/zww8/kMlkSKVSxONxnjx5wr/7MTabjffee4+pqSmq1SqqqjIyMsKxY8eIRCIMDw8zOzuLz+frWbxdF6LrujkDisUilUqFbDbLn3/+yeLiIoVCgfX1dTKZDJVKBVEUEUWRer1OrVZjZWUFh8NhCqlUKmxublIulzl+/DgTExM9FWLbp2P2n2sZVVXZ3t5mdXWV77//nlQqxaNHj8jlcqTTaQzDwDAMZFnG7XYzODhIIBDgyZMnPH/+HLvdjt1uN2eOzWbDZrPh8/nwer1cv36daDT6hh93B7vWMh3PEE3TqNVq1Go1UqkUlUqFVCrFysoKT58+pVQqIQgCExMTRKNRnE4nkiQhiiIulwtFUfB6vczOzpLJZFheXubZs2eUy2VqtZr5Po1GA1VV0XW905BfScdCVFUlFovx22+/8c0331CpVGg2m7RaLRqNBoFAgGg0ysWLF7l69Soejwe3220+3263Y7PZ0HUdwzC4ceMG165dIxaLkUwmOw3vP9OxEMMwaDQaVKtVSqUS1WoVXdex2+2IokggEGBubo5z587h8/lwOp04nU7z+e0l8e+lJAgCNtvOGe33+wkGg8iy3GnIr6QrQqrVKrVaDVVV0TQNAFEUOXr0KHNzc3zxxRf4fD4URXnpg7ZpjzudTux2+0vXpqenmZmZQVGUTkN+JR0LcTqdhEIhRFEkn8/TbDaBF0Lcbjdzc3N4vV5EUdxTBrzYizRNI5/Pk8/nzRzFZrMhCALDw8OEw2FcLlenIb+SjoVIksTp06cJh8N88MEH5nh7KQiCgCiK+75Oo9GgVCqxtrZGMpmkWq0CmM+PRCJEo9Ed+08v6FhI+1sXBGHH3tC+Zp3+e7G+vs7PP//M77//TqlUQtM0BEEgHA4zPj7OzMwMJ06ceOk9uk1XErP2bHidmbAXd+7c4auvvkLTNHRdx+FwIIoiFy9eJBqN8u6773LixIluhPtKep66WzEMA13XqdfrlMtlM2FbWFgwN2S73U4kEiESifDhhx8SjUZ7vpm2OXAhuq6jaRrZbJbHjx/z448/cvPmTbLZrHm7djgcXLhwgY8//phPP/2UkydPHlh8B1LtGoZBsVhkdXXVrGWSySSrq6ssLS2Ry+Wo1+vAi3zD7/dz+vRpzp8/z8DAQK9D3MGBlf/JZJLvvvuO5eVlHjx4gKqqO1LzNkNDQ0xPT3PhwgUmJyd7fpu1ciBLRtd1CoUCjx49Yn19HVVVzXzFSiaTIRaLcevWLeLxOMeOHcPj8TA2NobX62VwcLCnkg5syWxtbfHgwQM0TTM31t3IZDJkMhnW19dxu90oioLH4+HKlSucP3+eS5cuIcvyK5O8Tuh6+f/SC/y9ZDY2Nrh9+zblcplCoUCxWCSXy5mPi8fjLC0tmT0UURRxOp1mv2RqaorR0VE++ugjzpw5w9mzZ/F6vQiC8Nq5joVdjfZciJVarWbKWFtbM8d/+uknfvnlF1ZXV0mn07s+t91Ri0QifP3110xOTiJJEoIgvEkovemH/FecTieKoiDL8o7O19DQEJcuXWJtbY10Ok0mkyGXy3H//n3i8TjwYrYlEgmq1SrPnz9ncHCQ48ePv6mQXTlwIQ6HA4fDgcvlwuv1muPDw8NMT09TrVbNW/TKygrZbNYUArC5uUkulyMejxMKhTh69Gh34+vqq3VAuxBsd9VlWSYYDBKPx/nrr79IJBJsb28DL2bKxsYG8XicU6dOdTWOQ3Mu0y4EJUkye63BYJDZ2VmmpqZ2pO6GYZgzR1XVrsZxaITsRbtwtI55vd6eVL+HXgjAbndCt9uN3+/v6oYKh2gPsVIsFtne3mZhYYGHDx/uyFlsNhunTp0iEol01HLYjUMppF0MJpNJEokEiURiR2YrCAJDQ0P4/f6uH2seOiHVapVKpcK9e/e4c+cOf/zxh3lEATA5Ocn4+DiBQABZlt80S92TQyOk/YHr9TrZbJZYLMb8/DypVMq8ZrfbCQaDRCIRvF4vDoej6zXNoRFSKBRIp9Pcvn2bu3fv8vjxY5LJpNknGRgYwO12c/XqVS5fvszo6Oiu5zed8laFtCthwzDI5/M8ffqUhw8fcuPGDbO3Ci820SNHjjA4OMi5c+cIhUI9kQFvUYiqqqiqysbGBktLS9y9e5f5+XkSiQTNZtNcJi6XC1mW+fLLL/nkk08Ih8M9kwFdFvLvb9yaULXH2383Gg0KhQLxeJz5+XkWFha4d++e+fj2me/AwACKonD27FneeecdPB5Pz2RAF4Vomka1WqVcLrO2toaiKIyMjJiH3pVKha2tLUqlEpubmywvL7O4uGjWKfl8HvgnM41EIoTDYa5cuUI0GiUUCqEoSk9/PQRdFNJqtSiVSmxtbRGLxRgdHUWSJPMXRLlcjuXlZba2tsxl0u6tqqq645RPFEXGx8cJh8NEo1FmZmbMhlGv6ZqQfD7Pt99+SzKZ5P79++Zhd6vVotVqmecwqqqaM6ZSqZgb5/DwMGNjY7z//vtmk/nkyZMoioIkSV3PN/aia0IajQaJRIJnz56xuLj4Wj9ssdlsSJKEJEmMjY0RiUQ4c+YM0WiUiYkJ/H5/t8J7bbomxOPxcPnyZTweD7/++uu+QmRZ5siRI3z++ed89tlnhEIhRkZGcLlcB7Y8dqNrQhwOB8FgkHQ6TSAQMI8l98LlcuHz+ZicnGR2dpahoaEdHbS3RdeazK1WyzxvKRaL+7/x3w0ht9ttdsm6XcrvF8KugwfddT9E9P+j6nXoC7HQF2KhL8TCfrfd3lVRh5T+DLHQF2KhL8RCX4iFvhALfSEW/gcMlBno19ugeQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fast.ai command to display a tensor in image form.We note that three_tensors and seven_tensors are \n",
    "#list of tensors,so we index one image\n",
    "show_image(three_tensors[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of the tensor\n",
    "three_tensors[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#object type for three_tensors.\n",
    "type(three_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for every pixel position in the image,we will calculate average of the pixel value over all images\n",
    ".For this the images are converted into a 3 dimensional tensor.The individual tensors of the images we\n",
    "have are 2D tensors(as they contain rows and columns).Now since we stack them together in a single \n",
    "tensor,this forms another dimension.Pytorch provides a \"stack\" function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pytorch for some mathematical operations such as mean,the numbers should be float instead of \n",
    "integers.So the tensor values for images are converted into float.It can be done using.float() simply.\n",
    "Now since pixel values range from 0 to 255.So,we normalize pixel values by dividing them by 255 to\n",
    " get values between 0 and 1.It also shows gradient and is an indicator of the pixel intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6131, 28, 28])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stacking bunch of Image tensors together Covert it into a 3dcube of images\n",
    "#Convert values to float and divide by 255 to get normalized pixel values between 0 and 1\n",
    "#This is done for all the images in the sevens and threes list\n",
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "stacked_threes.shape\n",
    "# We print the shape of the stacked tensors.The third dimension shows that it is a 3d stack of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we print the shape of a tensor(.shape),it tells about the length of each axis in the tensor.\n",
    "Here we had 6131 total 3s images in the list each of which had 28*28 pixel values(2D).As such no \n",
    "definite order is followed that first axis is the number of images,second is pixel rows and third is\n",
    "pixel columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rank of a tensor by length of its shape\n",
    "len(stacked_threes.shape)\n",
    "#Rank of a tensor is the length of a tensor's shape.Shape gives the size of each axis of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rank is also known as the number of dimensions\n",
    "stacked_threes.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as we had mentioned before we calculate the mean of the pixel values to get a central value which\n",
    "can represent a \"3\".Mean is calculated along axis 0.This dimension indexes over all images so we \n",
    "compute the average for all the images at each pixel position.\n",
    "Fastai's \"show_image\" is used to show an \"ideal 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Mean of the 3s images across axis-0\n",
    "mean3 = stacked_threes.mean(0)\n",
    "show_image(mean3);#show image represents the tensor value as image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same mean along 0 axis is calculated for sevens and show_image is used to show an \"ideal 7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Mean of the 7s images across axis-0\n",
    "mean7 = stacked_sevens.mean(0)\n",
    "show_image(mean7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take a random image of \"3\" from the stacked_image dataset and display it.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sample 3s and seeing it's close to which baseline mean model\n",
    "a_3 = stacked_threes[1]\n",
    "show_image(a_3);\n",
    "#Its clear that it's similar to 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to compare this image with our ideal 3 to test if its similar to 3 or not.We need some \n",
    "metric to calculate the difference between the two.We cannot just take the mean difference since they \n",
    "may cancel out each other.If anyone has worked with Machine Learning,specifically regression..\n",
    "They must be aware of the metrics such as \"mean absolute difference\" and \"mean squared difference\".\n",
    "These metrics are used mostly to calculate distance between continuous values.The two metrics are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Mean Absolute Difference:Here mean of the absolute difference is calculated.Also called \"L1 Norm\".\n",
    "2.Mean Squared Difference:Here mean of the squares of the differences is calculated.This is also\n",
    "called \"L2 Norm\".Since this is of order 2,so most of the times we take square root of the value and it\n",
    "is called \"Root Mean Squared Error\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate both the metrics for calculating the distance between the sample image and our ideal 3 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1114), tensor(0.2021))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Metrics to see the error between the test_3 and our mean basline model for 3\n",
    "dist_3_abs = (a_3 - mean3).abs().mean()#Mean Absolute difference (L1 Norm)\n",
    "dist_3_sqr = ((a_3 - mean3)**2).mean().sqrt()#Root Mean square error(L2)\n",
    "dist_3_abs,dist_3_sqr #Displaying both the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1586), tensor(0.3021))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Metrics to see the error between the test and our mean basline model for 7\n",
    "dist_7_abs = (a_3 - mean7).abs().mean() #Mean Absolute difference (L1 Norm)\n",
    "dist_7_sqr = ((a_3 - mean7)**2).mean().sqrt() #Root Mean square error(L2)\n",
    "dist_7_abs,dist_7_sqr#Displaying both the errors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculated metrics for the distance of sample image from both \"ideal 3\" and \"ideal 7\".We can \n",
    "observe that both the errors have less values in case of 3 then with 7.Since the error is less with\n",
    "\"3\" , we can conclude that our sample image is \"3\" and hence our baseline model is good for this \n",
    "prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we calculated error by providing formula for calculation.But Pytorch provides packages for Loss\n",
    "functions.It provides it under \"torch.nn.functional\",which we can import it as F and can then use as \n",
    "below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1586), tensor(0.3021))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In built pytorch functions for L1 and RMSE \n",
    "F.l1_loss(a_3.float(),mean7), F.mse_loss(a_3,mean7).sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Arrays and PyTorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the start we mentioned that Numpy arrays and Pytorch Tensors have almost same functionalities\n",
    "except the fact that Pytorch supports GPU operations whereas numpy does not.This is critical for deep\n",
    "learning.\n",
    "We know python is a slow language.In these cases things like Numpy and Pytorch are very faster than \n",
    "pure Python and can finish complex calculations at much faster rate than Pure Python.\n",
    "Let us learn about basic differences between tensors and arrays:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy array is a container for n-dimensional data where all items are of same data type.Numpy provides\n",
    "various operators and methods for computations and that is why is popular for scientific programming.\n",
    "\n",
    "Pytorch tensors is same as Numpy array but it comes with additional functionalities too.It is same as\n",
    "numpy arrays that is n-dimensional data container with all items of same data type.It is different in\n",
    "this aspect that as we have nested arrays we do not have nested tensors.Also Pytorch objects are\n",
    "capable of working on GPU so computations are faster.Pytorch also provides packages for calculating\n",
    "gradients for any set of operations on Objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us learn about some basic operations on arrays and tensors:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting data into array and tensors\n",
    "data = [[1,2,3],[4,5,6]]\n",
    "arr = array (data)\n",
    "tns = tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr  # numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns  # pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[1]   #Accessing Tensor elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 5])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[:,1] #Tensor slice containing elements at 1st position in all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 6])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[1,1:3] #Slicing tensors 1st row and 1st and 2nd column elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 4],\n",
       "        [5, 6, 7]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Addition of a scalar to tensor\n",
    "tns+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns.type()#Type of tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5000, 3.0000, 4.5000],\n",
       "        [6.0000, 7.5000, 9.0000]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Multiplying a scalar  by tensor\n",
    "tns*1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the operations we showed on tensors have identical syntax for Numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Metrics Using Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have defined a baseline model for the digit classification.But how do we evaluate our model\n",
    "performance.We had a validation set also in the downloaded mnist sample subset.In general to avoid \n",
    "models from getting overfit,we evaluate their performance on validation set also.Since here we are\n",
    "using pixel similarity model which just calculates mean and is not getting trained on any data but \n",
    "still we can see how this model performs on validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us repeat the same process of converting images into list of tensors and then stacking the tensors\n",
    "to create a three dimensional tensor of images for the 3s and 7s images in validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Previous processing steps on validation set for evaluating baseline model performance\n",
    "#Validation 3 images converted into tensors which are then stacked into 3d image blocks\n",
    "valid_3_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255 #Pixels normalized between 0 and 1\n",
    "#Validation 3 images converted into tensors which are then stacked into 3d image blocks\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'7').ls()])#Pixels normalized between 0 and 1\n",
    "valid_7_tens = valid_7_tens.float()/255\n",
    "valid_3_tens.shape,valid_7_tens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last we check the shape of the stacked images and it is 3 dimensional with 0 axis of 1010 and 1028 \n",
    "length.These are the number of images in the Validation set.\n",
    "Now we want to find for each image in these stacked tensors if they are 3 or 7.We can write a function\n",
    "\"is_3\" which will see the error between the sample image tensor and the ideal 3 we calculated before.\n",
    "Since this is a binary classification problem so we need not check for 7.Earlier we saw that error was\n",
    "calculated using MAE and MSE.\n",
    "Now we write a simple function which takes two tensors as input and calculates the mean absolute error\n",
    "between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1114)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A simple function which accepts two tensors(in this case test image tensor and baseline mean tensor)\n",
    "# and calculates the mean absolute error along the x and y axes\n",
    "def mnist_distance(a,b): \n",
    "    return (a-b).abs().mean((-1,-2)) #mean over x and y axes(last and second last distance)\n",
    "mnist_distance(a_3, mean3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell we passed the single test image and the mean value for the \"ideal 3\" we calculated \n",
    "earlier.Both of these are tensors with shape(28*28).Above we passed a single image,but when we are\n",
    "doing it for validation set we need to pass every image tensor through the function.Traditional\n",
    "programming says that we can loop through the stacked tensor for every image and calculate the error.\n",
    "But that is a slow method.Numpy arrays use something called \"Broadcasting\" and even we can use the \n",
    "same.So next instead of passing only one tensor we pass the stacked three dimensional Image tensor\n",
    "directly.Let us see what output we get and what is it's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1280, 0.1623, 0.1242,  ..., 0.1508, 0.1263, 0.1260]),\n",
       " torch.Size([1010]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What happens wehn we pass whole stacked 3d stacked image tensor through the absolute error function\n",
    "valid_3_dist = mnist_distance(valid_3_tens, mean3)\n",
    "valid_3_dist, valid_3_dist.shape#Returns list of 1010 tensors and broadcasting happens to calculate \n",
    "#the difference between the two differently shaped tensors/arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we get a tensor with as many distance values as there were Images in \"valid_3_tens\".\n",
    "The shape of the output tensor also verifies the same.\n",
    "Now in mnist_distance function we are performing subtraction between two tensors at pixel level.But \n",
    "earlier when we passed both the tensors of same shape,it worked at pixel level.In the above cell we \n",
    "passed a tensor of different rank so it performs subtraction between tensors of different ranks using\n",
    "Broadcasting.It automatically expands the tensor with the smaller rank to have the same size as the\n",
    "one with larger rank and thus performs the calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see some of the basic operations on tensors of different ranks.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 4])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Addition operation between 2 same shaped tensors.Element wise addition occurs\n",
    "tensor([1,2,3]) + tensor([1,1,1]) #No broadcasting happens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in our case,we passed a rank-2 tensor representing a single image and the other stacked tensor had \n",
    "1010 stacked images in a 3d tensor so Pytorch extends the dimension of the rank-2 tensor and treats it\n",
    "as 1010 copies of the same.And Thus has the same shape as the stacked one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1010, 28, 28])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#subtraction between 2 differently ranked tensors as broadcasting happens \n",
    "#extra copies of the lower dimension tensor are created as many as the number of elements in higher dimension tensor\n",
    "(valid_3_tens-mean3).shape#Doesn't actually copy but pretends to copy while the mathematical operation happens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define function \"is_3\" which takes a tensor image as input and compares the distance(error)\n",
    "between the passed tensor and \"ideal 3\" and that of \"ideal 7\".It will return a binary output(True or\n",
    "False) on the basis which error is less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to predict if the passed tensor image is 3 or 7.\n",
    "def is_3(x): \n",
    "    return mnist_distance(x,mean3) < mnist_distance(x,mean7)\n",
    "#returns if the mean absolute error is greater with baseline model for 3 or that of 7 by calculating the error using mnist_distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(1.))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_3(a_3), is_3(a_3).float()#Passing a3 test through is_3 and it turns out it's True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next instead of single tensor of rank-2 we pass stacked tensor of rank-3 which returns a tensor \n",
    "containing Boolean values.Through broadcasting every image inside the stacked tensor is compared with\n",
    "mean_3 and mean_7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  ..., False,  True,  True])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#broadcasting the valid_3_tens set of all3 tensor and validating if they are 3 or not\n",
    "is_3(valid_3_tens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate accuracy for training and validation sets by taking average of the function for all \n",
    "3s and since it is binary problem accuracy of 7s is inverse of 3s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9168), tensor(0.9854), tensor(0.9511))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy for the predictions by baseline model on validation sets for 3s and 7s\n",
    "accuracy_3s =      is_3(valid_3_tens).float() .mean()\n",
    "accuracy_7s = (1 - is_3(valid_7_tens).float()).mean()\n",
    "\n",
    "accuracy_3s,accuracy_7s,(accuracy_3s+accuracy_7s)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing we have a 90% accuracy on both 3s and 7s using a baseline model.But here we are classifying \n",
    "only 2 digits.So we need a better model.\n",
    "To get a better model,we can remember the basic logic of deep learning we learnt in first chapter,the \n",
    "model improves its performance itself by updating the parameters and optimizes the same.Let us\n",
    "learn about the training process and SGD,the most common optimizer used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We had discussed in the first Chapter about the \"Machine Learning\" definition provided by Arthur \n",
    "Samuel.He had described it as a means of testing the model performane by assigning correct weights\n",
    "and then update the weights accordingly to maximise the model performance.In a way he provided the\n",
    "definition of \"Deep learning\".In this way model becomes better but in the earlier pixel similarity \n",
    "model,there is no weight assignment,no training of the model,no learning from data.We just used a \n",
    "central tendency approach and compare our test samples with that.So we cannot improve \"Pixel Similari\n",
    "ty Model\".\n",
    "\n",
    "How do we improve any Machine Learning model using weight assignment?.What are the steps involved and\n",
    "how weights are updated acc to model performance?.Previously we saw that Images are made up of pixels\n",
    "whose values are fed into a model while dealing with them.Weights are assigned to individual pixels \n",
    "and highest weights are assigned to those which are black.These weights determine the probability of\n",
    "the digit in the Image.They would be different for different digits.The probability can be defined as\n",
    "a function of Image vector(x) and the set of weights(w).\n",
    "pr_eight(x,w)=(x*w).sum()\n",
    "Our aim is to find a set of weights(w) which maximises the value of this function.So the steps to find\n",
    "the best set of weights can be summarized as :-\n",
    "1.Randomly Initialize set of weights.\n",
    "2.Using them predict for each Image if it is 3 or 7.\n",
    "3.Calculate loss on the basis of predictions.Use appropriate Loss function.\n",
    "4.Now calculate gradient which will show how the weights should change.\n",
    "5.Update the weights according to gradient.\n",
    "6.Again make predictions and repeat the process\n",
    "7.Continue doing the same till you find that your model is making correct predictions.\n",
    "\n",
    "We should note this that these steps are in general True for every Deep Learning model and that every \n",
    "model uses these steps to solve any complex problem ultimately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would apply the general steps for training Deep learning model we discussed above to train our\n",
    "Digit Classifier from scratch.But before that we can understand the basic functionalities or packages\n",
    "we would use while implementing these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimizing loss function using stochastic Gradient descent\n",
    "def f(x):\n",
    "    return(x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we defined a quatratic function which can act like our loss function.X can be assumed as our\n",
    "weight parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting function using fast.ai plotting function\n",
    "plot_function(f, 'x', 'x**2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned earlier first step would be randomly initializing our weights and making predictions \n",
    "and calculating loss.In the cell below the red point denotes our starting value of the loss.According-\n",
    "ly we will calculate gradient and update weights so that we reach the set if weights where loss \n",
    "function is minimum.In this case it is at the global minima of function at x=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Starting point for gradient descent(Randomly chosen x value)\n",
    "plot_function(f, 'x', 'x**2')\n",
    "plt.scatter(-1.5, f(-1.5), color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from the shape of the curve we can say that as we update the weights,the red point would keep \n",
    "sliding on the curve till it reaches x=0(global mimima).\n",
    "How do we update the parameters or weights?>We change the parameters by a small value in the direction\n",
    "of the slope of the curve.We repeat this a process many times until we reach the minimum of the \n",
    "function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This idea was given by \"Issac Newton\" and does not change no matter how complicated the functions \n",
    "become.It is called \"Gradient Descent\" and is considered basic method for optimizing any function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We looked above how we optimize the loss function by updating weights.The next step involves\n",
    "calculating gradient.It is also called \"slope\".It allows us to decide how to change our weights so \n",
    "that loss decreases.Gradient is also called \"derivative\" of any function if any of us remember that \n",
    "from our High School mathematics.\n",
    "More specifically \"Derivative\" is change in the value of a function divided by the change in the \n",
    "parameter.Calculus also provided shortcuts in the form of derivatives to calculate these gradients.\n",
    "Now as in our High School we would not have one function here with one parameter.Loss functions \n",
    "would have lots of parameters and with gradient we will get a gradient for every weight.So we would\n",
    "obtain a set of gradients for a set of weights.But it's notsomething complex.We calculate derivative\n",
    "with respect to one parameter while keeping others constant.In this way gradients for every weight are\n",
    "calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch provides a package which lets us calculate gradient for any function.It's very easy and fast\n",
    "too.Let's see how we calculate gradients using pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying requires_grad_() method of pytorch on xt so that everytime any operation is performed \n",
    "#it remembers it and calculates gradient\n",
    "xt = tensor(3.).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a tensor object x.The special method \"requires_grad()\" tells Pytorch about the gradient\n",
    "calculation.For every object we create for which we need to calculate the gradient,we tell Pytorch \n",
    "about this using requires_grad() method.\n",
    "Let us pass xt through a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Passing xt through f\n",
    "yt = f(xt)\n",
    "yt\n",
    "#Return squared value but also a gradient function which will be used for calculating the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell that while printing the output Pytorch also prints that it has a gradient function \n",
    "to calculate gradient whenever needed.Now we ask Pytorch to calculate gradient using .backward() \n",
    "method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method does backpropogation that is takes derivative\n",
    "yt.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Backward\" means backpropogation.It means calculating derivative for each layer in neural net.In the \n",
    "further chapters we would know how it is done when we build a neural network from scratch.There is one\n",
    "called \"backward\" pass and something called \"forward pass\" in which activations are calculated and \n",
    "neurons are activated.We would do that in future.Let's see how do we view the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grad method gives gradient(derivative of f at xt=3)\n",
    "xt.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a tensor with a single item 6 as gradient.Our function was y=x**2 so if we calculate derivative\n",
    "it should be 2*x and at x=3 it's value will be 6 which is what Pytorch calculates for us.Here we \n",
    "passed a single scalar value as a tensor.Let's see what happens when we pass a set of parameters as \n",
    "vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.,  4., 10.], requires_grad=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Passing f through a rank 1 tensor or a vector with 3 elements\n",
    "xt = tensor([3.,4.,10.]).requires_grad_()\n",
    "xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(125., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modifying f function to give sum of the x\n",
    "def f(x): \n",
    "    return (x**2).sum()\n",
    "yt = f(xt)\n",
    "yt\n",
    "#A sum is added to the function so that instead of a vector we get a scalar as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we repeat the same process we did earlier.\"backward\" calculates the gradient and \".grad\" \n",
    "calculates the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.,  8., 20.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Backpropogation and calculating gradient from grad function.\n",
    "yt.backward()\n",
    "xt.grad\n",
    "#It gives a vector with the derivative for each element in the tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculated gradients for our input xt=[3,4,10].We can see that the gradients are 2*xt the same\n",
    "values we expected.So we have learnt how to calculate gradients for a set of paramaters.But it doesn't\n",
    "tell us how we would change our parameters.Gradient only tells us that if it's very large,we need to\n",
    "update our weights by more amount or more no of times and if gradient is small,we need to make small\n",
    "updations as we may be near our global minima of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's learn how do we step up the parameters using gradient.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stepping With a Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate defines stepping the parametrs according to the gradients obtained.Gradients are \n",
    "multiplied by a number called \"Learning rate\" which is small in value(<1.).Learning rates are found by\n",
    "trial and error by trying a few and then deciding which fits our model best.Weights are adjusted \n",
    "according to the following equation:\n",
    "    w-=lr*gradient(w)\n",
    "Technically this step is called \"stepping the gradients\".Optimization rate depends on the learning \n",
    "rate.If \"lr\" is very small,then we need to update weights many times and it will take time to reach \n",
    "the minima with small steps but if we have very high learning rate it can update very fast and \n",
    "sometimes it may pass our minima point and become very high.This will result in model becoming worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An End-to-End SGD Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw how we update our parameters to reach the minima of the loss function.But we did not see  a \n",
    "complete example till now where we optimize a function for a set of parameters and reach its minima.\n",
    "Let us see a complete example now:\n",
    "We take a simple example of measuring speed of a roller coaster as it climbs up the hill.Initially \n",
    "it would be fast but it would get slow as it reaches up.The speed would be minimum at the peak and \n",
    "would increase again as it starts moving down.We build a model which measures speed with time.If the \n",
    "speed changes every 20 secs,we can define time as follows:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a tensor with 20 values representing time variable at which speed can be measured\n",
    "time = torch.arange(0,20).float(); \n",
    "time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a quadratic function for speed using random values.We plot it against time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#defining the speed function\n",
    "speed = torch.randn(20)*3 + 0.75*(time-9.5)**2 + 1\n",
    "plt.scatter(time,speed);\n",
    "#Plot speed against time and plot results in a convex function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since here we don't know how the actual function for speed look like we define a quadratic function \n",
    "of the form (a*time**2 + b*t +c) with parameters a,b and c.Now our input variable is time(t) and our\n",
    "function parameters(a,b and c).Using both we can calculate the speed of the roller coaster.Let's \n",
    "define a function which takes time(t) and parameters a,b,c as input and returns the speed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which returns the value of the function with the passed parameters at a passed value of time\n",
    "def f(t, params):\n",
    "    a,b,c = params\n",
    "    return a*(t**2) + (b*t) + c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our main aim is to find best set of values for a,b and c.Quadratic function is considered to be \n",
    "the simplest one and thus optimizing it will help us in finding parametrs for more complex functions \n",
    "in neural nets.\n",
    "For best set of parameters we define a loss function which returns difference between the predictions\n",
    "and target speed.It returns difference so we try to minimize the loss function to find best a,b and c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the loss function returning the mean squared error between the \n",
    "#passed target and predicted values\n",
    "def mse(preds, targets): \n",
    "    return ((preds-targets)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have discussed the main mechanism behind the process like calulating gradients,updating the \n",
    "weights and optimizing the loss function.Let's follow each and every step from the starting now.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Initialize the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before first we initialize our parameters to random values.Since we have a,b and c ,3 \n",
    "parameters so we initialize a vector of 3 random items with requires_grad() method provided by Pytorch\n",
    "since we will calculate gradients further in process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting with SGD\n",
    "#Step-1 Initializing random gradients with required_grad_() to calculate the gradient\n",
    "params = torch.randn(3).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "orig_params = params.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Calculate the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we calculate our predictions by passing the randomly initialized parameters in the \n",
    "earlier step.We pass the parametrs and time vector through the prediction function declared earlier.\n",
    "It returns the speed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step-2 calculate the speed prediction using the function f defined above\n",
    "preds = f(time, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next since we have made our predictions we define a function to see how close or how far are our \n",
    "predictions and targets are from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function which takes predictions as input and plots predictions and target together\n",
    "def show_preds(preds, ax=None):\n",
    "    if ax is None: ax=plt.subplots()[1]\n",
    "    ax.scatter(time, speed)\n",
    "    ax.scatter(time, to_np(preds), color='red')\n",
    "    ax.set_ylim(-300,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call the function to plot target and predictions together and see how accurate are our \n",
    "predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEACAYAAABcXmojAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAb50lEQVR4nO3df6xc5Z3f8ffHNsKOL3cdlru0dmW7YTc4a8BB3Ih2gxK0pLGSZlvL7h+wN7tG6spoI0dVQTSkYOomWARS/5NtmuAWYqBeldA17BKSRYmC1QVt0w5FBm5lqAi+DmbDXnvhxtc25te3f5wzw3g8P33OnPn1eUlHnvs8z8x57vHc+c7z8ygiMDMzA1jQ6wqYmVn/cFAwM7MKBwUzM6twUDAzswoHBTMzq3BQMDOzCgcFMzOryDUoSNoqqSTplKTdNXnXSDog6YSkJyWtqsqTpLskHU2PuyUpz7qZmVlrebcUXgPuAO6rTpR0AbAX2AacD5SAh6qKbAE2AOuAy4AvADfkXDczM2sh16AQEXsj4lHgaE3WRmA6Ih6OiLeA7cA6SWvS/M3Azoh4NSIOAzuB6/Osm5mZtbaooPOsBfaXf4iI45JeTtMP1Oanj9fWeyFJW0haFixduvSKNWvW1CtmZmYNPPPMM0ciYqJeXlFBYQyYrUmbA86ryp+ryRuTpKjZnCkidgG7ACYnJ6NUKnWnxmZmQ0rSTKO8omYfzQPjNWnjwLEG+ePAfG1AMDOz7ioqKEyTDCIDIGkpcFGafkZ++ngaMzMrVN5TUhdJWgwsBBZKWixpEfAIcImkTWn+7cBzEXEgfeoDwI2SVkhaDtwE7M6zbmZm1lreLYXbgJPALcAX08e3RcQssAnYAbwBXAlcW/W8e4DHgOeBF4DH0zQzMyuQBrnb3gPNZmadk/RMREzWy/M2F2ZmVuGgYGZmFQ4KZmZW4aBgZmYVRa1o7huPPnuYbz7xIq+9eZLly5Zw8/qL2XD5il5Xy8ysL4xUUHj02cN8de/znHznPQAOv3mSr+59HsCBwcyMEes++uYTL1YCQtnJd97jm0+82KMamZn1l5EKCq+9ebKjdDOzUTNS3UfLly3hcJ0AsHzZkh7Uxsysc90eFx2plsLN6y9myTkLT0tbcs5Cbl5/cY9qZGbWvvK46OE3TxJ8MC766LOHczvHSAWFDZev4M6Nl7Ji2RIErFi2hDs3XupBZjMbCEWMi45U9xEkgcFBwMwGURHjoiMXFLLyOgcz65UixkVHqvsoqyL688xsuD367GE++Y2f8g9veZxPfuOnHX1+FDEu6qDQAa9zMLMssn6xLGJc1N1HHfA6BzPLotkXy3Y/2Ls9LuqWQgca9dt5nYOZtWMQvlgWGhQk7ZP0lqT59HixKu8aSQcknZD0pKRVRdatHV7nYGZZDMIXy160FLZGxFh6XAwg6QJgL7ANOB8oAQ/1oG5NeZ2DmWUxCF8s+2VMYSMwHREPA0jaDhyRtCYiDvS0ZjW8zsHMzlb5s6Ofp7X3IijcKekbwIvArRGxD1gL7C8XiIjjkl5O0/sqKGTldQ5mo63fv1gWHRS+Avxf4G3gWuAxSR8HxoDZmrJzwHm1LyBpC7AFYOXKld2sa+58Pwcz63eFjilExM8i4lhEnIqI+4Gngc8D88B4TfFx4Fid19gVEZMRMTkxMdH9SufI6xzMBl+WxWeDoNdTUgMQMA2sKydKWgpclKYPjUGYjmZmjY3CrgaFBQVJyyStl7RY0iJJU8CngCeAR4BLJG2StBi4HXiu3waZsxqE6Whm1tgotPaLbCmcA9xBMnZwBPgysCEiXoyIWWATsAN4A7iSZMxhqAzCdDQza2wUWvuFDTSnH/yfaJL/E2BNUfXphUGYjmZmjY3C3Rv7ZZ3CyOj36Whmwy7LtPCb11982gxCGL7WvoOCmY2MrNPCR6G176BgZiNjEHYp7TUHhQHjFdE26rL8DYzCQHFWDgoDxCuibdRl/RsYhYHirHq9eM06MApzpM2ayfo34GnhrbmlMEDyaPq6+8kGWda/gVEYKM7KQWGAZG365tH95KBivZRH98+wDxRn5e6jAZK16Zu16T0K+75Yf3P3T/e5pTBAsjZ9sza985jOZ5altenun+5zUBgwWZq+WZvens5nWeXRhenun+5y99EIydr0zmOX12Hfi96a8wy6/ueWwgjJ2vTOuu+LB7qHgxePDTcHhRGTpemdNahkHZPw4r3e8+Kx4eegYB3JElQ80D34sv4fjMIuo4POQcEK44Hu/tDL7h/PHup/DgpWmKzfEvPoehiGMYksv0M/dP949lB/G73ZR3v2wOrVsGBB8u+ePb2u0cjYcPkK7tx4KSuWLUHAimVLuHPjpR0NdGeZPTUMi++y/g7eO8ha6ZuWgqTzgXuBz5Lcw/mrEfGnuZ5kzx7YsgVOnEh+nplJfgaYmmr/NW69FQ4dgpUrYceO9p9rAz3QDdlbGlmfn/V3cPePtdI3QQH4NvA2cCHwceBxSfsjYjq3M9x66wcBoezEiSS9nQ92B5We6+VAd9aulzxmT2X9Hdz9Y630RfeRpKXAJmBbRMxHxFPAXwB/kOuJDh3qLL1Ws6DSjnJQmZmBiA+CiruwCpF18V3Wrpc8Fm5l/R3c/WOt9EVQAD4KvBcRL1Wl7QfW1haUtEVSSVJpdna2s7OsXNlZeq1eBxXLJOsHYtZv6XnMnsr6O2Qd17Hh1y9BYQyYq0mbA86rLRgRuyJiMiImJyYmOjvLjh3woQ+dnvahDyXp7eh1UAEPlGeQ9QMx67f0PLYJyeNDfcPlK3j6lt/llW/8U56+5XcdEOw0/TKmMA+M16SNA8dyPUu57/5s+/R37Dh9TAE6DyozM/XT25HHmMaIy9IfnnVKbV4Lt9ynb93ULy2Fl4BFkn6rKm0dkN8gc9nUFBw8CO+/n/zbyYfp1BTs2gWrVoGU/LtrV2dBJUtLxd1PPZX1W7q7bmwQKCJ6XQcAJP03IIA/Ipl99EPgd5rNPpqcnIxSqVRMBfOSZfbRggXJAHUtKQly3T6/mQ0FSc9ExGS9vH7pPgL4EnAf8LfAUeCPc52O2i+mps7+Q9jdT2bWZf3SfURE/F1EbIiIpRGxMveFa8PA3U9m1mV9ExSsDVnHNPKY/WRmQ81BYdBkGSjPOqUWPCXWbMg5KIySrN1PXpFtNvQcFEZJ1u4nj0mYDb2+mZJ6NgZySuogy2NKrJn1XLMpqW4pWPvyGJMws77moGDtyzomAR6oNutzDgrWvqxjEh6oNut7HlOw4qxeXX9F9qpVyfRaMyuExxSsP3jxnFnfc1Cw4nig2qzvOShYcfIYqDazrnJQsOJkHagGz14y67J+2jrbRkGWrcO99bdZ17mlYIPD22yYdZ2Dgg0Oz14y6zoHBRscnr1k1nWFBAVJ+yS9JWk+PV6syb9G0gFJJyQ9KWlVEfWyAePZS2ZdV2RLYWtEjKXHxeVESRcAe4FtwPlACXiowHrZoMhj9pKZNdUP3UcbgemIeDgi3gK2A+skrelttawvZbnzHHhKq1kLRQaFOyUdkfS0pKur0tcC+8s/RMRx4OU0/QyStkgqSSrNzs52s742bLwhn1lLRQWFrwAfAVYAu4DHJF2U5o0BczXl54Dz6r1QROyKiMmImJyYmOhWfW0YeUqrWUuZg0I6iBwNjqcAIuJnEXEsIk5FxP3A08Dn05eYB8ZrXnYcOJa1bman8ZRWs5YyB4WIuDoi1OC4qtHTAKWPp4F15QxJS4GL0nSz/HhKq1lLXe8+krRM0npJiyUtkjQFfAp4Ii3yCHCJpE2SFgO3A89FxIFu181GjKe0mrVUxJjCOcAdwCxwBPgysCEiXgSIiFlgE7ADeAO4Eri2gHrZqPGUVrOWfOc1s07s2ZMMTB86lHQ77djhoGIDp9md17xLqlm7vEurjYB+WLxmNhg8pdVGgIOCWbs8pdVGgIOCWbs8pdVGgIOCWbs8pdVGgIOCWbs8pdVGgGcfmXUiyz2mzQaAWwpmZlbhoGBWJN/Pwfqcu4/MiuLFbzYA3FIwK4oXv9kAcFAwK4oXv9kAcFAwK4oXv9kAcFAwK4oXv9kAcFAwK4oXv9kA8OwjsyJ58Zv1ObcUzMysIpegIGmrpJKkU5J218m/RtIBSSckPSlpVVWeJN0l6Wh63C1JedTLbCh5AZx1UV4thddI7sN8X22GpAuAvcA24HygBDxUVWQLsAFYB1wGfAG4Iad6mQ2X8gK4mRmI+GABnAOD5SSXoBAReyPiUeBoneyNwHREPBwRbwHbgXWS1qT5m4GdEfFqRBwGdgLX51Evs6HjBXDWZUWMKawF9pd/iIjjwMtp+hn56eO1NCBpS9pVVZqdne1Cdc36mBfAWZcVERTGgLmatDngvAb5c8BYo3GFiNgVEZMRMTkxMZF7Zc36mhfAWZe1DAqS9kmKBsdTbZxjHhivSRsHjjXIHwfmIyLa+QXMRooXwFmXtQwKEXF1RKjBcVUb55gmGUQGQNJS4KI0/Yz89PE0ZnYmL4CzLstrSuoiSYuBhcBCSYsllRfGPQJcImlTWuZ24LmIOJDmPwDcKGmFpOXATcDuPOplNpSmpuDgQXj//eRfBwTLUV5jCrcBJ4FbgC+mj28DiIhZYBOwA3gDuBK4tuq59wCPAc8DLwCPp2lmZlYwDXLX/eTkZJRKpV5Xw8xsoEh6JiIm6+V5mwuzUeMV0daEN8QzGyW+Jai14JaC2SjximhrwUHBbJR4RbS14KBgNkq8ItpacFAwGyVeEW0tOCiYjRKviLYWPPvIbNT4lqDWhFsKZmZW4aBgZmYVDgpmZlbhoGBmnfE2GUPNA81m1j5vkzH03FIws/Z5m4yh56BgZu3zNhlDz0HBzNrnbTKGnoOCmbXP22QMvbzu0bxVUknSKUm7a/JWSwpJ81XHtqp8SbpL0tH0uFuS8qiXmeXM22QMvbxmH70G3AGsB5Y0KLMsIt6tk74F2ACsAwL4MfBz4Ls51c3M8uRtMoZaLi2FiNgbEY8CR8/i6ZuBnRHxakQcBnYC1+dRLzMz60yRYwozkl6V9D1JF1SlrwX2V/28P02rS9KWtKuqNDs72626mpmNpCKCwhHgE8Aq4ArgPKB6CeQYMFf18xww1mhcISJ2RcRkRExOTEx0qcpmZqOpZVCQtC8dKK53PNXq+RExHxGliHg3Il4HtgKflTSeFpkHxqueMg7MR0SczS9kZn3O22T0tZYDzRFxdc7nLH/Yl1sC0ySDzP8r/XldmmZmw8bbZPS9vKakLpK0GFgILJS0WNKiNO9KSRdLWiDp14FvAfsiotxl9ABwo6QVkpYDNwG786iXmfUZb5PR9/IaU7gNOAncAnwxfXxbmvcR4C+BY8ALwCnguqrn3gM8Bjyf5j+eppnZsPE2GX1Pg9x1Pzk5GaVSqdfVMLN2rV6ddBnVWrUKDh4sujYjS9IzETFZL8/bXJhZcbxNRt9zUDCz4nibjL7nm+yYWbG8TUZfc0vBzMwqHBTMzKzCQcHMzCocFMzMrMJBwczMKhwUzGyweEO9rvKUVDMbHN5Qr+vcUjCzweEN9brOQcHMBoc31Os6BwUzGxwrV3aWbh1zUDCzweEN9brOQcHMBoc31Os6zz4ys8HiDfW6yi0FMzOryBwUJJ0r6V5JM5KOSXpW0udqylwj6YCkE5KelLSqKk+S7pJ0ND3ulqSs9TIzs87l0VJYBPwC+DTwa8A24PuSVgNIugDYm6afD5SAh6qevwXYAKwDLgO+ANyQQ73MzKxDmYNCRByPiO0RcTAi3o+IHwCvAFekRTYC0xHxcES8BWwH1klak+ZvBnZGxKsRcRjYCVyftV5mZta53McUJF0IfBSYTpPWAvvL+RFxHHg5TT8jP328lgYkbZFUklSanZ3Ns+pmZiMv16Ag6RxgD3B/RBxIk8eAuZqic8B5DfLngLFG4woRsSsiJiNicmJiIr/Km9lo8IZ6TbUMCpL2SYoGx1NV5RYADwJvA1urXmIeGK952XHgWIP8cWA+IuIsfh8zs8bKG+rNzEDEBxvqOTBUtAwKEXF1RKjBcRUkM4iAe4ELgU0R8U7VS0yTDCKTll0KXMQH3Uun5aePpzEzy5s31Gspr+6j7wAfA34vIk7W5D0CXCJpk6TFwO3Ac1XdSw8AN0paIWk5cBOwO6d6mZl9wBvqtZTHOoVVJFNIPw78UtJ8ekwBRMQssAnYAbwBXAlcW/US9wCPAc8DLwCPp2lmZvnyhnotZd7mIiJmgKaLzSLiJ8CaBnkB/Jv0MDPrnh07Tr9JD3hDvRre5sLMRoc31GvJG+KZ2WjxhnpNuaVgZmYVDgpmZlbhoGBmZhUOCmZmVuGgYGZmFQ4KZmZW4aBgZtaJId9l1esUzMzaVd5ltbwiurzLKgzN2ge3FMzM2jUCu6w6KJiZtWsEdll1UDAza9cI7LLqoGBm1q4dO5JdVasN2S6rDgpmZu0agV1WPfvIzKwTQ77LqlsKZmZWkcftOM+VdK+kGUnHJD0r6XNV+aslRdVtOuclbavKl6S7JB1Nj7slNb2Tm5mZdUce3UeLgF8AnwYOAZ8Hvi/p0og4WFVuWUS8W+f5W4ANwDoggB8DPwe+m0PdzMysA5lbChFxPCK2R8TBiHg/In4AvAJc0eZLbAZ2RsSrEXEY2Alcn7VeZmbWudzHFCRdCHwUmK7JmpH0qqTvSbqgKn0tsL/q5/1pmpmZFSzXoCDpHGAPcH9EHEiTjwCfAFaRtB7OS8uUjQFzVT/PAWONxhUkbZFUklSanZ3Ns/pmZiOvZVCQtC8dKK53PFVVbgHwIPA2sLWcHhHzEVGKiHcj4vU077OSxtMi88B41SnHgfmIiHr1iYhdETEZEZMTExMd/8JmZtZYy6AQEVdHhBocV0Eygwi4F7gQ2BQR7zR7yfTfcktgmmSQuWwdZ3Y9mZkNhz7fejuvxWvfAT4GfCYiTlZnSLoSeBP4f8CHgW8B+yKi3GX0AHCjpB+SBIybgD/JqV5mZv1jALbezmOdwirgBuDjwC+r1iKUf8OPAH8JHANeAE4B11W9xD3AY8Dzaf7jaZqZ2XAZgK231aDrfiBMTk5GqVTqdTXMzNqzYAHU+8yV4P33C6uGpGciYrJenre5MDMrygBsve2gYGZWlAHYettBwcysKAOw9ba3zjYzK1Kfb73tloKZmVU4KJiZWYWDgpmZVTgomJlZhYOCmZlVOCiYmVmFg4KZmVU4KJiZWYWDgpnZIOny/Ri8otnMbFAUcD8GtxTMzAZFAfdjcFAwMxsUhw51ln4WHBTMzAZFAfdjcFAwMxsUBdyPIZegIOm/SvobSb+S9JKkP6rJv0bSAUknJD2Z3te5nCdJd0k6mh53S1Ie9TIzGyoF3I8hr5bCncDqiBgH/hlwh6QrACRdAOwFtgHnAyXgoarnbgE2AOuAy4AvADfkVC8zs+EyNQUHDyb3dD54MPd7M+QSFCJiOiJOlX9Mj4vSnzcC0xHxcES8BWwH1klak+ZvBnZGxKsRcRjYCVyfR73MzKwzua1TkPSfSD7MlwDPAj9Ms9YC+8vlIuK4pJfT9AO1+enjtU3Os4WkdQEwL+nFs6zyBcCRs3xuEVy/bFy/7Pq9jq7f2VvVKCO3oBARX5L0ZeAfA1cD5ZbDGDBbU3wOOK8qf64mb0ySIiLqnGcXsCtrfSWVImIy6+t0i+uXjeuXXb/X0fXrjpbdR5L2SYoGx1PVZSPivYh4CvgHwB+nyfPAeM3LjgPHGuSPA/P1AoKZmXVXy6AQEVdHhBocVzV42iI+GFOYJhlEBkDS0jRvul5++ngaMzMrXOaBZkm/IelaSWOSFkpaD1wH/DQt8ghwiaRNkhYDtwPPRcSBNP8B4EZJKyQtB24CdmetVxsyd0F1meuXjeuXXb/X0fXrAmXtpZE0Afx3km/4C4AZ4FsR8Z+rynwG+I8kgxs/A66PiINpnoC7gPLahv8CfMXdR2ZmxcscFMzMbHh4mwszM6twUDAzs4qhDgqSzpf0iKTjkmYk/X6Tsv9a0i8lzUm6T9K5Xa7buZLuTet1TNKzkj7XoOz1kt6TNF91XN3N+qXn3SfprapzNlwo2IPrN19zvCfpTxqULeT6SdoqqSTplKTdNXkN9/+q8zptv2/zqJ+kfyTpx5L+TtKspIcl/f0mr9P2+yKn+q1Op8BX//9ta/I6RV+/qZq6nUjre0WD1+nK9cvLUAcF4NvA28CFwBTwHUlnrJZOZ0zdAlwDrAY+Avz7LtdtEfAL4NPAr5HsDfV9SasblP/riBirOvZ1uX5lW6vOeXG9Ar24ftXXguT/9yTwcJOnFHH9XgPuAO6rTlTr/b9qtfW+zat+wIdJZsqsJpkMcgz4XovXavm+yLF+Zcuqzvn1Jq9T6PWLiD0178cvAT8H/k+T1+rG9cvF0AYFJeshNgHbImI+XVT3F8Af1Cm+Gbg33cPpDeDrdHn/pYg4HhHbI+JgRLwfET8AXgHqfrvoc4Vfvxr/Avhb4K8KPOcZImJvRDwKHK3JarX/V0WH79tc6hcRP0rr9quIOEEyU/CTWc+XV/060YvrV8dm4IFBnUE5tEEB+CjwXkS8VJXWaF+levsvXSjp17tYv9NIupCkzo0W7l0u6YiSrcm3SSrq/tp3pud9ukmXS6+vXzt/hL26flBn/y+gvP9XrU7et93yKVovIG3nfZG3GUmvSvpe2vqqp6fXL+0W/BTJ+qtmenH92jLMQaF2TyU4fc+lZmXLj+uVzZ2kc4A9wP1Vi/qq/Q/gEuA3SL4FXQfcXEDVvkLSFbSCpHvhMUkX1SnXs+snaSVJF9z9TYr16vqVZXkvNiubO0mXkSwwbXZ92n1f5OUI8AmSrq0rSK7FngZle3r9gD8E/ioiXmlSpujr15FhDgqt9lxqVrb8uF7ZXElaADxI0ge6tV6ZiPh5RLySdjM9D3yNpMukqyLiZxFxLCJORcT9wNPA5+sU7dn1I/kjfKrZH2Gvrl+VLO/FZmVzJek3gR8B/yoiGnbFdfC+yEXaDVSKiHcj4nWSv5PPSqq9TtDD65f6Q5p/QSn8+nVqmIPCS8AiSb9VldZoX6V6+y+9HhFn3bfZDkkC7iUZENsUEe+0+dQAenF3ukbn7cn1S7X8I6yj6OvXav+vap28b3OTdnv8BPh6RDzY4dOLvp7lbsJ65+zJ9QOQ9ElgOckOD53o1d9zXUMbFNJ+273A1yQtTf/D/jnJt/JaDwD/UtJvS/owcBvF7L/0HeBjwO9FxMlGhSR9Lh1zIB2c3Ab8eTcrJmmZpPWSFktaJGmKpK/0iTrFe3L9JP0OSRO82ayjwq5fep0WAwuBheVrR+v9vyo6fN/mUj9JK0j2Kvt2RHy3xWt08r7Iq35XSrpY0oJ0nOpbwL6IqO0m6sn1qyqyGfiziGjYKunm9ctNRAztQTL971HgOHAI+P00fSVJM3NlVdkbgdeBX5FMxzu3y3VbRfIN4a20LuVjqrZ+wH9I63acZKrb14Bzuly/CeB/kzS73wT+J/BP+uX6pee8B3iwTnpPrh/JrKKoObaneZ8huanUSWAfye1ry8/7t8CPWr1vu1U/4N+lj6vfh/P16tfsfdHF+l1HMjPvOPA3JF9C/l6/XL80b3F6Pa6p87xCrl9eh/c+MjOziqHtPjIzs845KJiZWYWDgpmZVTgomJlZhYOCmZlVOCiYmVmFg4KZmVU4KJiZWcX/B/G7ml6Pd3tgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Calling the show_preds function to plot target and predicted speeds together\n",
    "show_preds(preds)\n",
    "#It can be observed that using random values the predictions are pretty bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions and targets are not at all close and even shows having a negative speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Calculate the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we calculate the loss using the loss function declared earlier.We pass the predictions and the \n",
    "target speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25823.8086, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the loss by passing the predictions and target through the mse function\n",
    "loss = mse(preds, speed)\n",
    "loss\n",
    "#Very high loss is obtained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Calculate the gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate gradients using .backward() and then view it using .grad method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-53195.8594,  -3419.7146,   -253.8908])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we calculate the gradient by using backpropogation and then grad method\n",
    "loss.backward()\n",
    "params.grad#Gradient with respect to parameters is calculated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a lower learning rate and multiply the gradient by learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5320, -0.0342, -0.0025])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiply the gradient by learning rate\n",
    "params.grad * 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7658, -0.7506,  1.3525], requires_grad=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Step the weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we step our parameters using the gradient calculated and the learning rate.\n",
    "Now in the equation .data is used with params because Pytorch actually remembers every operation so as\n",
    "to calculate gradient on it later on.Here in this step we do not want Pytorch to calculate gradient \n",
    "for stepping our gradients and therefore we use.data method to update the parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating the weights(parameters) using the learning rate and gradient\n",
    "lr = 1e-5\n",
    "params.data -= lr * params.grad.data #.data is used when we don't want the gradient to be calculated\n",
    "params.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us repeat the earlier steps again that is get predictions,get the loss function and see\n",
    "how close the predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5435.5366, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding new predictions using the updated parameters and calculating the loss using the new predictions and target\n",
    "preds = f(time,params)\n",
    "mse(preds, speed)\n",
    "# It can be observed that loss decreases drastically thus showing that weights are updated in correct direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the new predictions with the target speed\n",
    "show_preds(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process has to be repeated many times so lets create a function to step our parameters(update\n",
    "the weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function for making predictions using passed parameters,calculating loss function value\n",
    "#the gradient, then updating the weights according to the value of the loss function\n",
    "def apply_step(params, prn=True):\n",
    "    preds = f(time, params)#get predictions\n",
    "    loss = mse(preds, speed)#calculate loss\n",
    "    loss.backward()#calculate gradients\n",
    "    params.data -= lr * params.grad.data#update the parameters\n",
    "    params.grad = None\n",
    "    if prn: \n",
    "        print(loss.item()) #print loss\n",
    "    return preds#return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Repeat the process "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using loop we iterate over this process and repeat this several times to reach minimum of our \n",
    "loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5435.53662109375\n",
      "1577.4495849609375\n",
      "847.3780517578125\n",
      "709.22265625\n",
      "683.0757446289062\n",
      "678.12451171875\n",
      "677.1839599609375\n",
      "677.0025024414062\n",
      "676.96435546875\n",
      "676.9537353515625\n"
     ]
    }
   ],
   "source": [
    "#repeating the process continuously by calling the apply_step function and \n",
    "#calculating the loss function value after each iteration\n",
    "for i in range(10): apply_step(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "params = orig_params.detach().requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is definitely decreasing on each iteration.But after certain iterations ,it decreases at very\n",
    "small rate.Let us see this visually by plotting predictions and target together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1QAAADMCAYAAAB0vOLuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhrklEQVR4nO3df4zc9Z3f8efbOBd7DXs+hAPBxOsruoMKEoJwlDagJiKqoBeSWnBSaDZXOInb6C70chfiYGSgHI3PBkKbRKS5bHIRBVYXGgmoknBBugOugkpVlvwiRhCJgh2bpDgUDGYNCfjTP2bWu7Pe+X7nx3dmvvOd50Ma7e73M7P73dl9zXfe38/n+/lESglJkiRJUvtWDHoHJEmSJGlYWVBJkiRJUocsqCRJkiSpQxZUkiRJktQhCypJkiRJ6pAFlSRJkiR1yIJKkiRJkjpUaEEVEVdGxGxEvB4Rty9p+2BEPBkRcxHxUERMLGqLiLgpIl6o326OiChy36RhY56kYpkpqVhmSqopuofqOeBzwDcWb4yIE4B7gOuA44FZ4O5Fd5kCNgNnAe8CLgI+UfC+ScPGPEnFMlNSscyURMEFVUrpnpTSfcALS5ouBnallL6VUnoNuAE4KyJOr7dfBtyaUtqbUtoH3ApcXuS+ScPGPEnFMlNSscyUVNOva6jOAH48/0VK6VXg6fr2o9rrn5+BpOWYJ6lYZkoqlpnSSFnZp59zLLB/ybYDwHGL2g8saTs2IiKllBY/KCKmqHUVs2bNmnNOP/10pEF47LHHfpVSWjeAH11YnsBMqTzMlFSsKmTKPKkssvLUr4LqIDC+ZNs48EqT9nHg4HIHqpTSNDANsGnTpjQ7O1v83kotiIjdA/rRheUJzJTKw0xJxapCpsyTyiIrT/0a8reL2oWHAETEGuDU+vaj2uuf70LScsyTVCwzJRXLTGmkFD1t+sqIWAUcAxwTEasiYiVwL3BmRFxSb78e+ElK6cn6Q+8APh0R6yPiZOAq4PYi900aNuZJKpaZkoplpqSaonuorgUOAVuBj9c/vzaltB+4BNgOvAi8F7h00eO+CnwbeBz4KfDd+jZplJknqVhmSiqWmZKAaDIEfCg4llaDFBGPpZQ2DXo/imSmNEhmSipW1TJlnjRIWXnq1zVUkiRJklQ5/Zrlr2/u++E+bnngKZ576RAnr13NlgtOY/PZ6we9W9LQMlNSscyUVCwzpUGrVEF13w/3cc09j3PoN28CsO+lQ1xzz+MABkvqgJmSimWmpGKZKZVBpYb83fLAU0cCNe/Qb97klgeeGtAeScPNTEnFMlNSscyUyqBSPVTPvXSore1SMw4fqDFTKoJ5WmCmVAQztcBMqQjdZqpSPVQnr13d1nZpOfPDB/a9dIjEwvCB+364b9C71ndmSt0yT43MlLplphqZKXWriExVqqDacsFprH7LMQ3bVr/lGLZccNqA9kjDyOEDC8yUumWeGpkpdctMNTJT6lYRmarUkL/5rrmsLju7yZXH4QMLzJS6ZZ4amSl1y0w1ysuUeVKeIjJVqYIKasFqFhRngtG8rBfYk9euZt8yIRrV4QNmSq1olinzdDQzpVaYqdY1y5R50rxev++r1JC/PHaTC/LHyjp8oHVmSpCdKfPUHjMlMFNFMU+C/rzvG6mCym5yQf4L7Oaz17Pj4neyfu1qAli/djU7Ln6nZ7OWYaYE2ZkyT+0xUwIzVRTzJOjP+77KDfnLYje5oLUX2KwhOVpgpgT5mTJPrTNTAjNVFPMk6M/7vpHqobKbXOAUq0UyUwIzVSQzJTBTRTFPgv7kaaQKqla69O774T7O3fkgv7v1u5y788GRXdehynyBLU5epszTaDBTxTFTAjNVFN/3CfqTp5Ea8gfOrqTWpi1W65xdSWaqWGZKZqo4vu9TP/I0cgVVlryLQDU88tadcPx575mnajFTg2emqsVMDZ6ZqpasTPU6TxZUizgbTDV4xqkczFN1mKlyMFPVYabKwUxVx6AzNVLXUOXxItBqcN2JcjBP1WGmysFMVYeZKgczVR2DzpQF1SJeBFoNnnEqB/NUHWaqHMxUdZipcjBT1THoTDnkbxEvAh0uzcbKuu5EOZin4WOmys1MDZes6znMVDmYqeFS5kxZUC3hRaDDIWus7JYLTmtoA884DYp5Gh5majiYqeGQdz2HmSoPMzUcyp4pC6o25M3Io2JlPd9ZY2Uf3Xr+kfv4tyo3M9VfZqr6zFR/NXu+82aPs2dkeJip/un0GFWGTFlQtWjQs4eMmrznO2+srGecys9M9ZeZqj4z1V9Zz3cr13OYqfIzU/3T7TFq/n4d/11mZmDbNtizBzZsgO3bYXKy5Yc7KUWLWpk9xNW2i5P3fDszz/AzU/1lpqov729snoqV9Xybp2owU/3T82PUzAxs3AgrVtQ+zsw0tk1Nwe7dkFLt49RU431yWFC1KK8ynq+s9710iMRCZb04XAavdXnPtzPzDL9uM2We2mOmqi/rb+wxqnhZz7d5qgYz1T89PUblFUzbtsHcXONj5uZq21tkQdWivMq4lbMYecHTgrzne/PZ69lx8TtZv3Y1Aaxfu5odF7/TLvgh0k2mzFP7zFT1Zf2NPUYVL+v5Nk/VYKb6p5BjVLNeqLyCac+e5Xeq2fZleA1Vi/JmD8mrrPMuphtFWRcftjJbi+PPh1s3mTJPyzNToy3rb/yXd/9o2cd4jMrWTabM0/AzU8VrlqmWjlFPPMzmv1l0ndM7tsPZ9euc5nuh5gun+V4oyC+YNmyo3X+pDRta/r0sqFqUN3tI3vz3rQxvGqVZZPIuPhz0bC3qvW4y1crFqWbKTI2arL/xLQ881dUxCsyUmRo9ZqpYeZlaf/+9vOO2/8TbXtrP82vX8fPPXMd7zr6w9uCsgmlyMrsXKq9g2r698XsDjI3VtrfIgqoNWWeb8irrrDeHrcwiM6yh63RKWfDs3ijoNFN5BzIzVWOmRk+zv3E3xyjIz1TV8gSt9TCYqeozU+35/vbbeMfnlxRF264Eapn61z/6Bz77P+/g5Jd/xXPjJ3Dzv/r33LLmt9j8xMO856+vPlLUnPTS85z011fDxt/JL5gmJ7N7oe68M7tgmp/Nz1n+Bi9vbGfWxXRVHYebtd+tnLnRaMvKVN7FqWZqgZkSdHeMgmpe05i332ZKWUY2Uxmz5X1/+22c+Vef4aSXnmcFiZNeep4z/+ozfH/7bQBsevR+dn7vNk55eT8rSJzy8n52fu82Nj16f/fXOTUbnrdhQ60wmp6GiQmIqH2cnm4smCYn4dln4fDh2sc2iimASCm19YAy2bRpU5qdnR30brSs2dmG3936XZb7KwTwzM4Pce7OB5c9y7F+7eojC24O6kxG1s/N2m8g93cqu4h4LKW0adD7UaRhylTW/163mRrkmUEzZaYGpdNMNTsTX4ZjVNbPznsdaOXYW3ZVy9Qw5QlKnKm8NZeatc/M8MYVf8LK1xb27Y1Vq1n59a/B5CS//J0TOeml54/6cb9c+zZOevH/Zrcf2F+bge+oJyRqRc7GjcsP25uYqBVAS4cEQq0Xamnh1IWsPJWmhyoijo+IeyPi1YjYHREf6+gbZc0zP2Cbz17Po1vP55mdH+LRrec3XCuynHauv+rlmYxm0352c3bPKWV7r+qZapYn6C5Tg8rTfJuZKi8zdbRWrmksa6ZcSmCwCssTVDJTH9n1EI985Y/5Pzd9mEe+8sd8ZNdDDZl65MYvcveOS3n6pg9z945LeeTGLy7873ez5lK9aFrc/sYVfwIzM8xtubqhmAJY+doh5rZcDcDbXtq/7O80v/3EA8u3n3hgf3YPE9SKurGxxralw/byeqF6qDQFFfBl4NfAicAk8JWIOKOt79DKwlwlDF3ei3YRU7ZnrYPQ6cGom0XYnFK2LwafqQHlrZtMFbHgcKcnIcxU6ZU/Uz3KXFamuj1GQf5xqNOTEN0svmumeq77PEFLBUJXmelRHrdccBp/+NQ/NRRNf/jUP7HlgtO47JlHlx0ad9kzjwLwo51f5sbvfKmh/cbvfIkf7fxyZkEE5A6tyyqaVv3iuWX/BPPbn1+7btn2+e3RpGiK+V6wbgumLoftdaMUQ/4iYg3wInBmSuln9W13AvtSSlubPe6ort8iugPzukF7JKvrdumFi1A7kM2/sGd1G/+Xj74787F53ztryMNz9QPYcj/3mZ0fyv3ew67MQylKkSkYaN46zdRf3v2jrv6vs9qbTaYxP4wjb6iimRqcochU3jGu02E+dc0uNu/mGJX3fw10fIzKy1Te8bEKypqpwvIE2ZlqNntbO5npYR6bDZ+b23I1Y784ugd37u3rGXtuL3t/+22c8vLRvT17x9dx/JrfynxsWrGCWOa9f4ogDh/mcKxgxTKpOUzw3PgJTX/uKQeeP3IN1erfvH6k7dBb3spP/+PnaxNTdPsaNWBZeSpLQXU28L9SSqsXbfsM8P6U0oebPe6oYK1YUfrxl53q1XUV3RyMyj5uvtfKeqCCkmQKSn2Co1fXVXRzEqLM10v2g5nqMlODemM5OZk5s9e5Ox/knEfvP2pmr8fO/YMjmWnWDmQ+dpivl+yHsmaqsDxBdqaaTZfdSmby2qF333vPnszXiayiB2jatiIdzr3OKatY+/qFV/DZe/4zY28sFExzK9/KzRd/mhvu/msge5Y/oPRFU5asPJVl2vRjgQNLth0Ajlt6x4iYAqYANiztOsybZz5vhpC8KRkH+E/Q6fTSeQvP5Y0hz5r204VCS60cmcpqayVvWWtOdJnHTqfCzctMVnveNLpmqtTKn6msx+blrZt2yJzu+AtvPsGZD9x25Kz1KS/v56YHbuOn/2IjcD6bHr2fHd+77cibtPnhTdfUf0zztvM5ee3qzGJsywWn8ciNX+QvHrz9SPsXzr+c867/FJCzUKh6qZg81TY2z1Renrpt79X3znmdeO3tJy/bC/Xa20/m/73662ULoufGT+AUYMd5f9SQKagVRTvO+yO+CE2Lpq9feAXv3vpJrv/1G0fnaesnj9z3PduuhHoBdVL91mBycmgKqHaU5Rqqg8D4km3jwCtL75hSmk4pbUopbVq3bslYzbzxl3kXvGX9c7cy7n1AssZ5540Rz2vPGjfv+PJSG3ymuskbZL+B62Ee8/6vu8lU3rVdZqrUyp+prPZevrHMK7a+9vmGIUAAq3/zOu/52ucBuOaROxvevAGMvfE61zxyZ2YbwBfefIKbHmi81uSmB27jC28+AdQKpuWuRdn8xMPFXHddwmtIh0QxeYLsTHWTmbz2Xn7vnNeJsVtu4o1VjceaN1atZuyWm/j6hVcwt/KtDW3zBRHA7Ll/wNYLr2Tv+DoOE+wdX8fWC69ktn4S4t1bP8n1F/15Q/v1F/057976STafvZ7zrv8UH73mm5x69bf56DXf5LzrP+UxCiClNPAbsIbahYm/t2jbHcDOrMedc8456Sh33ZXSxERKEbWPd93V2DY2llLtpbN2GxtbuM/ERGPb/G1iIrutxO79wd50+rV/nyau/s6R2+nX/n269wd7W2qfv8/7dvxj2nj1d9L7dvxjQ9soA2ZTCfKz3K0UmeombynVft5y7fP7kZfHrP3uQreZMk/NmanUXaay2vMy0017VlZTym0/3KT9cERmW9f7nffYbp7vvMfm/R+08n/SwutbWTNVaJ6yno9u/oZ57b383q38jZu03/uDvemqzVvSz8fXpTeJ9PPxdemqzVt831eArDwNPFRHdgS+CfxdPWTnUuv6PSPrMU2DlaXTA1neASPvew9QXjAMTmfKeqCav5UmU704wZGXxyLezGQwU71hpuq6eSM9iDeWvSzWujnxktee99hhLtbqypypUuSp2/Zefu8ueIzqjWEpqI4H7gNeBfYAH8t7TEfBytPsn7vbF0dVTpkPVKlMmcrSacHV7Rs481pKZqrHevXmb5C9ABZrRz92kTJnaujzpJEzFAVVJ7e+BqvbF3VVTpkPVJ3eSnew6vQNXLdvZkra21x1ZmqIDaoXwGLt6McuUrVMjUyeVEoWVEXJelEf4iGB6kzVDlRp2A5WWXnq5s2MvVcDY6bUEYu1xscuUrVMmScNkgVVPzjEaORU7UCVypapbnTzZqaVNyueHOkJM6XSGcZibZGqZco8aZAsqPrBIYEjp2oHqlS2THWr0zczRUx4oY6YKY2UXk6GUFe1TJknDVJWnsqyDtXwm5ysrRg/MVFbyXpiYmGFeehscThJnZucrK1Gf/hw7ePihQSz8pq3dkjOmjuA689Iypf1GpXXnvdYSX1lQVWkrBe4vDdpvgGT+qtZXvMWXs07OVLiRcAlSVLxLKj6JetNmm/ApPLI623utgfLkyeSJFWKBVW/ZL1Ja2UIkaT+yept7qYHy5MnkiRVjgVVPzV7k+b1VdLw6KYHy5MnkiRVjgVVGeQNIQKHCUll0mkPVisnT8y6JElDxYKqDPKGEDlMSBoe3cwgaNYlSRo6FlRlkDeEyGFC0nDpdAZBsy5J0tCxoCqLrCFEXmMlVUMR69U5JFCSpFJZOegdUAs2bKgN/Vluu6ThMjnZfBHOvKzPDwmc78WaHxI4/30lSVLf2UM1DPKGCYFnraUq6HZIoK8DkiT1nQXVMMgbJuSF7FI1dDMk0NcBSZIGwoJqWGRdY+WF7FJ1ZGXdNa4kSSodC6oqcNIKaTR0u8aVJEkqnAVVFbSyMLCk4dfNGlfgNVaSJPWABVUVtDJphaRq6HSNK6+xkiSpJyyoqqCVSSs8Ky1VmwuES5I0EBZUVdHsrLVnpaXR0e0C4Z58kSSpbRZUVedZaUmQf42VJ18kSeqIBVXVOfOXJOh+0WBJkrQsC6qqcwZASdDdosHgcEBJkpqwoKo6ZwCUNK/TRYMdDihJUlMWVFWXd1YaPPMsKfvki8MBJUlqyoJqFGSdlfbMsyTIPvnitZiSJDVlQTXqPPMsaV6zky+tXItpT7ckaURZUI06zzxLypN3LaY93ZKkEWZBNeqcBVBSnrxrMe3pliSNMAuqUecsgJJakXUtpj3dkqQRZkE16lqZBVCSsuT1dHt9lSSpwgopqCLiyoiYjYjXI+L2Zdo/GBFPRsRcRDwUEROL2iIiboqIF+q3myMiitgvtSjrzDP4ZmgAzJSGSlZPd0murzJTUrHMlLSgqB6q54DPAd9Y2hARJwD3ANcBxwOzwN2L7jIFbAbOAt4FXAR8oqD9UrdK8mZoBJkpDY+snu7yXF9lpqRimSmprpCCKqV0T0rpPuCFZZovBnallL6VUnoNuAE4KyJOr7dfBtyaUtqbUtoH3ApcXsR+qQDleTM0UsyUhk6znu6SXF9lpqRimSlpQT+uoToD+PH8FymlV4Gn69uPaq9/fgZNRMRUvYt5dv/+/T3YXTUoyZshNTBTGh7DMZOomZKKVVimzJOGQT8KqmOBA0u2HQCOa9J+ADi22VjalNJ0SmlTSmnTunXrCt9ZLTEcb4ZGjZnS8BiOmUTNlFSswjJlnjQMcguqiHg4IlKT2yMt/IyDwPiSbePAK03ax4GDKaXUyi+gHhuON0NDxUxppPRhJlEzJRXLTEntyS2oUkofSClFk9t5LfyMXdQuOgQgItYAp9a3H9Ve/3wXKgenVS+cmdLIyZtJtEtmSiqWmZLaU9S06SsjYhVwDHBMRKyKiJX15nuBMyPikvp9rgd+klJ6st5+B/DpiFgfEScDVwG3F7FfKkiP3wzpaGZKKpaZkoplpqQFRV1DdS1wCNgKfLz++bUAKaX9wCXAduBF4L3ApYse+1Xg28DjwE+B79a3aRi4RlWvmCmpWGZKKpaZkupimIerbtq0Kc3Ozg56N0bX/BpVi6dVHxsbmSGBEfFYSmnToPejSGZKg2SmpGJVLVPmSYOUlad+zPKnqnKNKkmSJI04Cyp1zjWqJEmSNOIsqNQ516iSJEnSiLOgUudco0qSJEkjzoJKnXONKkmSJI24lfl3kTJMTlpASZIkaWTZQ6Xecp0qSZIkVZg9VOqdpetU7d5d+xrs1ZIkSVIl2EOl3nGdKkmSJFWcBZV6x3WqJEmSVHEWVOod16mSJElSxVlQqXdcp0qSJEkVZ0Gl3nGdKkmSJFWcs/ypt1ynSpIkSRVmD5UkSZIkdciCSoPjor+SJEkacg7502C46K8kSZIqwB4qDYaL/kqSJKkCLKg0GC76K0mSpAqwoNJguOivJEmSKsCCSoPhor+SJEmqAAsqDYaL/kqSJKkCnOVPg+Oiv5IkSRpy9lBJkiRJUocsqFReLvwrSZKkknPIn8rJhX8lSZI0BOyhUjm58K8kSZKGgAWVysmFfyVJkjQELKhUTi78K0mSpCFgQaVycuFfSZIkDQELKpWTC/9KkiRpCHRdUEXEWyPibyNid0S8EhE/jIh/s+Q+H4yIJyNiLiIeioiJRW0RETdFxAv1280REd3ulypgchKefRYOH659HJFiykxJxTJTUrHMlNSoiB6qlcDPgfcDvw1cB/z3iNgIEBEnAPfUtx8PzAJ3L3r8FLAZOAt4F3AR8IkC9ksaVmZKKpaZkoplpqRFui6oUkqvppRuSCk9m1I6nFL6DvAMcE79LhcDu1JK30opvQbcAJwVEafX2y8Dbk0p7U0p7QNuBS7vdr+kYWWmpGKZKalYZkpqVPg1VBFxIvD7wK76pjOAH8+3p5ReBZ6ubz+qvf75GUh5ZmZg40ZYsaL2cWZm0HvUE2ZKKpaZkoplpjTqCi2oIuItwAzw31JKT9Y3HwscWHLXA8BxTdoPAMc2G0sbEVMRMRsRs/v37y9u5zVcZmZgagp274aUah+npipXVJkpqVhmSipWrzNlnjQMcguqiHg4IlKT2yOL7rcCuBP4NXDlom9xEBhf8m3HgVeatI8DB1NKabn9SSlNp5Q2pZQ2rVu3LvcXVEVt2wZzc43b5uZq20vOTEnFMlNSscqUKfOkYZBbUKWUPpBSiia386A2Wwvwt8CJwCUppd8s+ha7qF10SP2+a4BTWegWbmivf74LKcuePe1tLxEzJRXLTEnFMlNSe4oa8vcV4J8DH04pHVrSdi9wZkRcEhGrgOuBnyzqFr4D+HRErI+Ik4GrgNsL2i9V1YYN7W0fPmZKKpaZkoplpqS6ItahmqA21eW7gV9GxMH6bRIgpbQfuATYDrwIvBe4dNG3+CrwbeBx4KfAd+vbpOa2b4exscZtY2O17UPOTEnFMlNSscyU1Ghlt98gpbQbyFyMLaX0D8DpTdoS8Nn6TWrN/CK/27bVhvlt2FArpiqw+K+ZkoplpqRimSmpUdcFlTQwk5OVKKAkSZI0vApfh0qSJEmSRoUFlSRJkiR1yIJKkiRJkjpkQaVqmpmBjRthxYrax5mZQe+RJEmSKshJKVQ9MzMwNQVzc7Wvd++ufQ1OYiFJkqRC2UOl6tm2baGYmjc3V9suSZIkFciCStWzZ0972yVJkqQOWVCpejZsaG+7JEmS1CELKlXP9u0wNta4bWystl2SJEkqkAWVqmdyEqanYWICImofp6edkEKSJEmFc5Y/VdPkpAWUJEmSes4eKkmSJEnqkAWVJEmSJHXIgkqSJEmSOmRBpdE0MwMbN8KKFbWPMzOD3iNJkiQNISel0OiZmYGpKZibq329e3fta3AiC0mSJLXFHiqNnm3bFoqpeXNzte2SJElSGyyoNHr27GlvuyRJktSEBZVGz4YN7W2XJEmSmrCg0ujZvh3Gxhq3jY3VtkuSJEltsKDS6JmchOlpmJiAiNrH6WknpJAkSVLbnOVPo2ly0gJKkiRJXbOHSpIkSZI6ZEElSZIkSR2yoJIkSZKkDllQSZIkSVKHLKik5czMwMaNsGJF7ePMzKD3SJIkSSXkLH/SUjMzMDUFc3O1r3fvrn0NzgwoSZKkBvZQSUtt27ZQTM2bm6ttlyRJkhaxoJKW2rOnve2SJEkaWYUUVBFxV0T8IiJejoifRcQVS9o/GBFPRsRcRDwUEROL2iIiboqIF+q3myMiitgvqSMbNrS3vQfMlFQsMyUVy0xJC4rqodoBbEwpjQMfAT4XEecARMQJwD3AdcDxwCxw96LHTgGbgbOAdwEXAZ8oaL+k9m3fDmNjjdvGxmrb+8dMScUyU1KxzJRUV0hBlVLalVJ6ff7L+u3U+tcXA7tSSt9KKb0G3ACcFRGn19svA25NKe1NKe0DbgUuL2K/pI5MTsL0NExMQETt4/R0XyekMFNSscyUVCwzJS0o7BqqiPivETEHPAn8Ari/3nQG8OP5+6WUXgWerm8/qr3++RlIgzQ5Cc8+C4cP1z4OYHY/MyUVy0xJxTJTUk1h06anlP4sIv4D8C+BDwDzZy2OBfYvufsB4LhF7QeWtB0bEZFSSkt/TkRMUesqBjgYEU812aUTgF+1+3uMOJ+z9kzk36VzZqoSfM7aY6aUxeerfUOfqTbyBP6PtMvnqz1N85RbUEXEw8D7mzQ/mlI6b/6LlNKbwCMR8XHgT4EvAQeB8SWPGwdeqX++tH0cOLjcQar+M6aB6Rb2ezaltCnvflrgc9YfZmp0+Jz1h5kaDT5f/VOmTLWap/p++z/SBp+v4uQO+UspfSClFE1u5zV52EoWxtHuonbRIQARsabetmu59vrnu5AqykxJxTJTUrHMlNSerq+hioi3RcSlEXFsRBwTERcA/w54sH6Xe4EzI+KSiFgFXA/8JKX0ZL39DuDTEbE+Ik4GrgJu73a/pGFlpqRimSmpWGZKalTENVSJWhfv31Ar0HYDf5FS+h8AKaX9EXEJcBtwF/C/gUsXPf6rwD8DHq9//fX6tm611D2sBj5n5WCmqsPnrBzMVDX4fJWHmaoGn6+CRJMh4JIkSZKkHIVNmy5JkiRJo8aCSpIkSZI6VLmCKiKOj4h7I+LViNgdER8b9D6VTURcGRGzEfF6RNy+pO2DEfFkRMxFxEMR0dM1LFR+ZiqbeVK7zFQ2M6V2malsZqr3KldQAV8Gfg2cCEwCX4kIV99u9BzwOeAbizdGxAnAPcB1wPHALHB33/dOZWOmspkntctMZTNTapeZymameqxSk1LU1zl4ETgzpfSz+rY7gX0ppa0D3bkSiojPAaeklC6vfz0FXJ5Sel/96zXUVtA+e9FUpxohZqp15kmtMFOtM1NqhZlqnZnqnar1UP0+8OZ8oOp+DHiWojVnUHu+AEgpvQo8jc/fKDNTnTNPWo6Z6pyZ0nLMVOfMVEGqVlAdCxxYsu0AcNwA9mUY+fxpKf8nOudzp+X4f9E5nzstx/+LzvncFaRqBdVBYHzJtnHglQHsyzDy+dNS/k90zudOy/H/onM+d1qO/xed87krSNUKqp8BKyPi9xZtOwvYNaD9GTa7qD1fwJGxtKfi8zfKzFTnzJOWY6Y6Z6a0HDPVOTNVkEoVVPWxn/cAN0bEmog4F/i3wJ2D3bNyiYiVEbEKOAY4JiJWRcRK4F7gzIi4pN5+PfATL0wcXWYqn3lSO8xUPjOldpipfGaq9ypVUNX9GbAaeB74O+BPU0pW2o2uBQ4BW4GP1z+/NqW0H7gE2E5txpz3ApcOaidVGmYqm3lSu8xUNjOldpmpbGaqxyo1bbokSZIk9VMVe6gkSZIkqS8sqCRJkiSpQxZUkiRJktQhCypJkiRJ6pAFlSRJkiR1yIJKkiRJkjpkQSVJkiRJHbKgkiRJkqQOWVBJkiRJUof+P7vS4KUhKx4DAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_,axs = plt.subplots(1,4,figsize=(12,3))\n",
    "for ax in axs: \n",
    "    show_preds(apply_step(params, False), ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we stopped after 10 iterations,but in practice training and validation loss is observed and \n",
    "other metrics such as entropy loss,accuracy or error_rate to see where to stop the model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the beginning we initialized our weights to be random or they come from pretrained model.(from \n",
    "transfer learning).Then in the next step we make our predictions using these weights.Now its very rare\n",
    "that in the starting only we get our predictions near to our target variable.That is why we use \n",
    "Gradient Descent to update our weights to train our model.\n",
    "After obtaining predictions we compare them with our targets(actual labels) using loss function.In \n",
    "case of continuous values it is mostly mean squared error but there are other loss functions too.It \n",
    "outputs a number which we are trying to minimize by updating our weights.It is the same number which \n",
    "we had plotted earlier.Now to minimize the value given by loss function,we make little adjustments to\n",
    "our weights.\n",
    "We update the weights using learning rate and by calculating the gradients.Pytorch provides special\n",
    "Autograd package for calculating gradients fastly.We update our weights according to the magnitude of \n",
    "the gradient.Weights are updated by multiplying gradients with learning rate which decides the step \n",
    "size.We keep repeating the process until we reach minima of our loss function and then we stop at that\n",
    "point.The set of weights used in the last iterations are considered to be the optimized ones.\n",
    "This process is termed as Gradient Descent as we descend towards the minima of our loss function using\n",
    "gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as we understood the whole process of Gradient Descent for optimizing our loss function,we can \n",
    "apply this on the MNISt dataset too.All the steps can be applied directly to MNIST except for the \n",
    "loss function.Let's define an appropriate loss function for MNIST data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our independent variables(x) are our images.We need to combine them into a single tensor and also\n",
    "change the dimension of the tensor to rank-2 tensor.Dimension is changed using view method in Pytorch.\n",
    "We pass the shape in the view method.-1 is a special parameter passed through view which fits the \n",
    "axis length such that all data fits in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating 3s and 7s into one matrix and changing the rank of the tensors from 3 to 2 using Pytorch's view method\n",
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28) #view(-1,28*28) 28*28 columns and no of rows same as original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the target variable for our training data.Since we are only considering 3s and 7s in our data\n",
    "so we use 1 as label for \"3\" and 0 for \"7\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12396, 784]), torch.Size([12396, 1]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Labelling the image with 1 for Three images and 0 for 7 images unsequeeze will add one dimension\n",
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is an object in Pytorch which is used to store data.It returns a tuple (x,y) containing \n",
    "indpendent(x) and dependent(y) variable.\"zip\" function combines x_train and y_train into tuple and \n",
    "combined with list it gives the list of tuples having x,y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting train_x and train_y into a dataset using zip which return a tuple\n",
    "dset = list(zip(train_x,train_y))\n",
    "x,y = dset[0] # returns a tuple with dependent and independent variable\n",
    "x.shape,y #y-label,x-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the same procedure for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeating the same process for validation data\n",
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a function for randomly initializing weights for each pixel in dataset.We pass size \n",
    "through the init_params function which returns a tensor of  passed size containing randomly\n",
    "initialized weights along with the .requires_grad().We are required to calculate gradients in future \n",
    "so we use requires_grad() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize parameters\n",
    "def init_params(size, std=1.0): \n",
    "    return (torch.randn(size)*std).requires_grad_()#tell pytorch to get gradients.required_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier we saw that the probability function for an image is given by \"weight*pixels\".But that is not\n",
    "enough because when pixels are zero,then the product will also be zero.And therefore a \"bias\" term is\n",
    "added which is also initialized randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28,1))#storing returned weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in the beginning of this chapter we saw that the probability function for an image is given by \n",
    "\"weight*pixels\".But that is not enough because when pixels are zero,then the product will also be zero\n",
    ".And therefore a \"bias\" term is added which is also initialized randomly using init_params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize bias term(b) for the equation wx+b\n",
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we introduced a bias term(b) also into the neural network.The equation thus becomes y=wx+b.\n",
    "Weights(w) and bias(b) together are called parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20.2336], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting prediction for one image\n",
    "#defining the equation(wx+b) Weights*input +Bias\n",
    "(train_x[0]*weights.T).sum() + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A for loop can be used to iterate over every image to calculate each prediction but it will take a \n",
    "lot of time.Also python loops don't run on GPU.As such also Python is considered slow language.\n",
    "In this case we can use matrix multiplication calculating w*x for every image in the row of matrix.\n",
    "Matrix multiplication can be represented by @ operator in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function linear below through which we pass our X_train.It calculates wx+b for every image\n",
    "in the data and gets the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.2336],\n",
       "        [17.0644],\n",
       "        [15.2384],\n",
       "        ...,\n",
       "        [18.3804],\n",
       "        [23.8567],\n",
       "        [28.6816]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#returning the predictions for the training set by matrix multiplication with weights and then bias added.\n",
    "def linear1(xb): \n",
    "    return xb@weights + bias #@ for matrix multiplication\n",
    "preds = linear1(train_x)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe from the first value in the predictions.It is the same as the one we previously \n",
    "calculated for first image separately.\"Wx+b\" or \"Weights*Input+bias\" is considered one of the \n",
    "fundamental equations of any neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check accuracy of the predictions we just check if they are greater than zero.Since 3s had label 1 \n",
    "and 7 had 0 so images which are 3 will have pred>0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [False],\n",
       "        [False],\n",
       "        [False]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Labelling our predictions with 0(not3) and 1(is3)\n",
    "corrects = (preds>0.0).float() == train_y\n",
    "corrects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the fraction of images which are predicted as 3 by taking mean of the \"True\" predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4912068545818329"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating fraction for predictions by taking the mean of 1s obtained\n",
    "corrects.float().mean().item()#.item( returs 0 ranked tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change weights a little to see the effect on accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating weights a little\n",
    "weights[0] *= 1.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next get the predictions for these set of weights and calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4912068545818329"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predictions and the changes in accuracy\n",
    "preds = linear1(train_x) #get predictions\n",
    "((preds>0.0).float() == train_y).float().mean().item() #calculating accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that small changes in weights do not effect accuracy that much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw previously in the steps for SGD that after getting predictions for our initialized set of \n",
    "weights,we need to update our weights to improve our model.For updating weights,we need gradients\n",
    "which are calculated using loss function which we try to minimize.\n",
    "We need appropriate loss function for this purpose.One option can be to use accuracy which is a metric\n",
    "but can be used as loss function as well.We would calculate predictions for each image,calculate \n",
    "overall accuracy and calculate gradient for each weight with respect to overall accuracy.\n",
    "But there is a problem with using accuracy as the loss function.We know that the gradient or slope is\n",
    "defined as the change in the dependent variable divided by the change in the parameters.\n",
    "slope=(y_new-y_old)/(x_new-x_old).We saw before that accuracy is not affected much by a small change \n",
    "in weights.So slope would be almost zero and thus accuracy if used as a loss function would have zero\n",
    "gradient.\n",
    "If gradients are zero,we won't be able to update the weights and thus model would not learn from the \n",
    "data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other loss functions should be used instead of accuracy which will give better predictions and \n",
    "better loss.Let's define a function which takes in arguments the predictions of the model whose\n",
    " value is between 0 and 1.The other argument this function takes is the targets which also lie between\n",
    "0 and 1.These predictions and targets are vectors(rank-1 tensors) and are indexed over images.Let's consider two such vectors containing the targets and the predictions for 3 random images.In these \n",
    "first is a 3,next a 7 and the other a 3.And now our predictions are such that the first image is \n",
    "predicted as 3 with high confidence(0.9),with less probability that the second image is 7 and an \n",
    "incorrect prediction that the last image is 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternate loss function for mnist dataset as accuracy cannot be used as \n",
    "trgts  = tensor([1,0,1]) #target labels\n",
    "prds   = tensor([0.9, 0.4, 0.2]) #predicted probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define a loss function which measures the difference between the predictions and the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for loss function call entropy function\n",
    "def mnist_loss(predictions, targets):\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here torch.where(a,b,c) is used.We have never used this function before but it's same as ternary \n",
    "operator in C.It states that b is the output if a is true else c is the output.In this case we can\n",
    "define it such that what would be the distance from 1 if the prediction is 1 and what would be the dis\n",
    "from 0 if its zero and then we would do average of all the distances or errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.4000, 0.8000])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss calculated for the predictions\n",
    "torch.where(trgts==1, 1-prds, prds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe from the loss function above that it returns a lower loss when predictions are correct\n",
    "and higher when the predictions are incorrect.Lower loss is always better and since loss value should\n",
    "be scalar therefore we take mean of the returned tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4333)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean of the losses\n",
    "mnist_loss(prds,trgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2333)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Small loss with better predictions\n",
    "mnist_loss(tensor([0.9, 0.4, 0.8]),trgts) #Works only when the predictions are between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since here scores are getting subtracted from 1,so this function would work well only when the \n",
    "predictions are between 0 and 1.While making predictions we are using equation wx+b which can return\n",
    "values in any range.So how do we ensure that the values are between 0 and 1.Let's look at a function \n",
    "for that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sigmoid function always returns values between 0 and 1.Mathematically it is (1/1+e^-x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a sigmoid function which ranges the numbers between 0 and 1 passing any number through the function\n",
    "def sigmoid(x): \n",
    "    return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this function looks like when plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_function(torch.sigmoid, title='Sigmoid', min=-4, max=4) #plotting sigmoid function using fastai's\n",
    "#plot_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the input values it is very clear that whatever the input is the output always lies between 0 and\n",
    "1.Also since its a smooth curve it is easy to find gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us modify mnist_loss such that sigmoid is applied to our predictions so they lie between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping predictions through the sigmoid function so that it maps values between 0 and 1\n",
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()\n",
    "#accuracy cannot be used to get gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this loss function would work with every prediction since sigmoid will map them between 0 and 1.\n",
    "We earlier discussed that why can't we use accuracy which is a metric as loss function.Let's dig into\n",
    "it more..\n",
    "Though it may sound that loss and metric both indicate same thing and can be used in each others place\n",
    "but that's not true.Metrics is something we just see to drive human understanding,just to make a \n",
    "judgement if the current model or current step in a model is going fine or not whereas loss is \n",
    "necessary to improve our model.We need loss to calculate gradients without which we can't update our \n",
    "weights and thus model won't be improved.Loss is calculated for every item in our dataset and then at \n",
    "the end of each epoch loss is averaged and mean value is printed.\n",
    "Metrics is something very important and tell us about the performance of our model.While evaluating\n",
    "model performance,we should concentrate on metrics value rather than loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD and Mini-Batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learnt about loss function and how it is used in the training phase to update the weights on the \n",
    "basis of gradients.We saw previously that loss is calculated for every item in the dataset and then\n",
    "all the values are averaged.But while learning process,if it is calculated separately for each item,\n",
    "training time would increase and if we use loss of just one item or a few more,it cannot represent the\n",
    "loss of whole dataset.Therefore a batch system is considered in which loss is calculated for few items\n",
    "at a time and it is called a mini-batch.No of items in a single batch is called batch size.It can be \n",
    "set manually and would remain same for every batch in that model.Batches containing more items would \n",
    "take longer time to learn but would be more accurate at the time of model building.\n",
    "Selecting a good batch size is also a crucial step while building model as it helps in getting a more\n",
    "accurate as well as fast model.Choosing a large batch size sometimes leads to memory running out.\n",
    "Setting mini batches is also a good method to get our model more generalized in case we test them on\n",
    "some outside data.\n",
    "Before putting model into Training we split the whole dataset into minibatches with random shuffling \n",
    "too.Pytorch amnd Fastai provides a DataLoader object which splits dataset automatically into\n",
    "mini batches of given batch_size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's create a DataLoader object for a simple numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([11,  9, 12, 14,  7]),\n",
       " tensor([ 8,  5, 10,  3,  2]),\n",
       " tensor([ 1,  6, 13,  0,  4])]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Doing a step for each image would be slow so we take multiple images together and update the weights\n",
    "#so batches of data are used to update the weights\n",
    "coll = range(15)\n",
    "dl = DataLoader(coll, batch_size=5, shuffle=True)#class from \n",
    "list(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we had discussed before about DataSet which is List of tuples containing dependent and independent\n",
    "variables.Let's create a DataSet and pass this to a DataLoader object.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#26) [(0, 'a'),(1, 'b'),(2, 'c'),(3, 'd'),(4, 'e'),(5, 'f'),(6, 'g'),(7, 'h'),(8, 'i'),(9, 'j')...]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tuples of lowercase letters\n",
    "ds = L(enumerate(string.ascii_lowercase))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([ 2, 13, 14,  6, 12,  8]), ('c', 'n', 'o', 'g', 'm', 'i')),\n",
       " (tensor([15, 16,  4, 19,  3, 21]), ('p', 'q', 'e', 't', 'd', 'v')),\n",
       " (tensor([ 7, 18, 17, 24, 10,  1]), ('h', 's', 'r', 'y', 'k', 'b')),\n",
       " (tensor([ 5, 20, 23, 25,  0, 22]), ('f', 'u', 'x', 'z', 'a', 'w')),\n",
       " (tensor([11,  9]), ('l', 'j'))]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dividing into batches using DataLoader\n",
    "dl = DataLoader(ds, batch_size=6, shuffle=True)\n",
    "list(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a Dataset ds containing tuples of lower case letters and their index.Next we passed it \n",
    "through a DataLoader to create batches of batch size 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting It All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the DataLoader we created to use it for training our model.We would be using the same 7 \n",
    "steps we had discussed earlier for SGD.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step-1:Initialize the parameters(weights,bias) using the \"init_params\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the weights and bias for 3 and 7 dataset\n",
    "weights = init_params((28*28,1))\n",
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step-2 Pass the dataset through DataLoader object to split it into batches of size 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading dset into DataLoader for splitting into batches\n",
    "dl = DataLoader(dset, batch_size=256)\n",
    "xb,yb = first(dl) #fast.ai function which grabs first index through a iterator\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next load validation set into different dataloader with same batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading validation data into the DataLoaders\n",
    "valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to see if our functions are working properly we slice 4 images from our training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 784])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grabbing first 4 images from training set\n",
    "batch = train_x[:4]\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass them through the linear1 function to get the predictions(wx+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1876],\n",
       "        [-8.3973],\n",
       "        [ 2.5000],\n",
       "        [-4.9473]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predictions for 4 images in batch by passing it throught the linear function(wx+b)\n",
    "preds = linear1(batch)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next after getting predictions we pass preds and targets through the mnist_loss function to get the \n",
    "loss calculated(cross entropy loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7419, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating cross entropy loss for the predictions\n",
    "loss = mnist_loss(preds, train_y[:4])\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next as per the regular procedure we calculate gradient using.backward() and take the mean of all the \n",
    "items in gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 1]), tensor(-0.0061), tensor([-0.0420]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Backpropogating the loss function \n",
    "loss.backward()#every pixel has a gradient\n",
    "weights.grad.shape,weights.grad.mean(),bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put all this together in a function so that we can pass the wholw batches together along with\n",
    "the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for calculating gradient from the loss  \n",
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test it by passing the first four images in our training data.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0121), tensor([-0.0840]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_grad(batch, train_y[:4], linear1)\n",
    "weights.grad.mean(),bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0182), tensor([-0.1260]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_grad(batch, train_y[:4], linear1)\n",
    "weights.grad.mean(),bias.grad\n",
    "#Calculating gradients twice it changes because .grad adds the gradients it calculates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call the function twice the value of the gradient changes.That is because loss.backward adds \n",
    "the gradients to the other gradients already stored.So the gradient should be set to zero first.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.grad.zero_() #A tensor of weights containing zeros\n",
    "bias.grad.zero_();#A bias containing zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods in Pytorch whose names end with a \"_\" are used for changing objects in place.It sets all the\n",
    "gradients to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as we have calculated gradients we need to update the weights and bias using learning rate.So we\n",
    "define a function to step the weights.This function also includes the calculating gardient step.So we \n",
    "define an overall function through which we pass model,learning rate and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, params):\n",
    "    for xb,yb in dl:#looping through each batch in dataloader\n",
    "        calc_grad(xb, yb, model)#calculate gradients for each batch\n",
    "        for p in params:#loop through params(weights,bias)\n",
    "            p.data -= p.grad*lr # doesn't update the gradients data attribute is used so that it \n",
    "#doesn't calculate the gradient for this step\n",
    "            p.grad.zero_()#zero the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how model is performing we will have to check the accuracy of the model.Since the model is \n",
    "classifying digits as 3 or 7,so accuracy can be just checked by checking if its greater than 0.5.\n",
    "Threshold is 0.5 due to the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To measure accuracy threshold changes to 0.5 due to Sigmoid function\n",
    "(preds>0.5).float() == train_y[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function to calculate batch accuracy.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for calculating accuracy of the batches\n",
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()# passing predictions through sigmoid\n",
    "    correct = (preds>0.5) == yb #get correct predictions\n",
    "    return correct.float().mean() #returns mean of the correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2500)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get accuracyfor every batch\n",
    "batch_accuracy(linear1(batch), train_y[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then put all the batches together now to train a complete epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl] #Passing every batch in validation \n",
    "    #set through the model and calculate batch_accuracy using the predictions\n",
    "    return round(torch.stack(accs).mean().item(), 4) #stacking the accuracies and calculating the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the function by passing the model \"linear1\" through the function.It returns the validation\n",
    "accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5263"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear1) #validation set accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first chapter we saw while building initial models that they are run for several epochs.Let's \n",
    "see if training the model for next epoch improves our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6664"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model for another epoch \n",
    "lr = 1.#Learning rate\n",
    "params = weights,bias#weights and bias\n",
    "train_epoch(linear1, lr, params) #training the epoch\n",
    "validate_epoch(linear1)#validating the epoch with validation set\n",
    "#accuracy changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observed that accuracy improves by more than 10% on running another epoch.So we further run a few\n",
    "more epochs to improve the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8266 0.89 0.9184 0.9277 0.9399 0.9467 0.9506 0.9526 0.956 0.9579 0.9599 0.9609 0.9614 0.9619 0.9633 0.9638 0.9648 0.9658 0.9672 0.9677 "
     ]
    }
   ],
   "source": [
    "#training and validating epochs for around 20 epochs\n",
    "for i in range(20):\n",
    "    train_epoch(linear1, lr, params)#train each epoch by passing model,learning rate,parameters\n",
    "    print(validate_epoch(linear1), end=' ')\n",
    "    #We can observe that the accuracy increases and becomes 96% after several epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attained an accuracy of about 97% which is similar to the \"pixel similarity approach\".Next \n",
    "an object can be created which would help in handling the SGD steps.Pytorch provides a special\n",
    "package called Optimizer for the same.But here we will be defining an optimizer from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch provides special packages for very often used models or functions.Previously we had defined a \n",
    "linear function for getting the predictions using equation wx+b where w=weights and b=bias.Weights\n",
    "and bias are called parameters.Using pytorch we can instead create nn.Linear module.Module is object\n",
    "inherited from Pytorch's nn.Module class.These objects have functionality similar to Python functions.\n",
    "On passing the shape of the parameters through the nn.Linear class it will return the activations\n",
    "of the model.It initializes the parameters on its own and we don't have to define separate function\n",
    "for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a model\n",
    "linear_model = nn.Linear(28*28,1)\n",
    "# A pytorch class which initialized the weights and biases and also calculates the predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 784]), torch.Size([1]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gives weights(w) and bias(b) as the parameters\n",
    "w,b = linear_model.parameters()\n",
    "w.shape,b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the parameters(weight and bias)using the parameters method of the nn.Linear object.Next\n",
    "we can use this to create an Optimizer.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create optimizer class which does the same steps for updating the parameters\n",
    "class BasicOptim:\n",
    "    def __init__(self,params,lr): \n",
    "        self.params,self.lr = list(params),lr # get parameters and the learning rate\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params:#iterate through the weights and bias in the parameters \n",
    "            p.data -= p.grad.data * self.lr #step the gradients\n",
    "\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None #make the previous gradient zero to avoid updation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined a class for Optimizer which takes the parameter and learning rate and it updates the\n",
    "parameters.(both weights and bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#passing parametrs and learning rate for creating an optimizer\n",
    "opt = BasicOptim(linear_model.parameters(), lr) #creating an object for Optimizer class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an object of BasicOptim class and pass the model parameters and learning rate.Next we can \n",
    "define a function to train an epoch now.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training an epoch\n",
    "def train_epoch(model):\n",
    "    for xb,yb in dl: #for every batch in dataloaders\n",
    "        calc_grad(xb, yb, model)#calculate gradient for the batch using the loss and predictions\n",
    "        opt.step()#Update the gradients\n",
    "        opt.zero_grad()#Make the previously stored gradients zero later(to avoid addition of graients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation function remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.461"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validating the epoch remains same\n",
    "validate_epoch(linear_model)\n",
    "#retrns the average accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we had defined train_epoch function which trains data for an epoch.One epoch means training\n",
    "all mini batches of data for one cycle.To improve the model accuracy , we train our model over several\n",
    "epochs so next we define a train_model function which takes model object and no of epochs as \n",
    "arguments and prints the accuracy for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting both in a function to train and iterate over the epochs\n",
    "def train_model(model, epochs):\n",
    "    for i in range(epochs):#iterating through each epoch\n",
    "        train_epoch(model) # training epochs\n",
    "        print(validate_epoch(model), end=' ')#printing the validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4932 0.7686 0.8555 0.9136 0.9346 0.9482 0.957 0.9634 0.9658 0.9678 0.9697 0.9717 0.9736 0.9746 0.9761 0.977 0.9775 0.9775 0.978 0.9785 "
     ]
    }
   ],
   "source": [
    "#Training our model for 20 epochs\n",
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass the linear_model and number of epochs as 20 through the train_model function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we had defined a Basic_Optim class for the optimizer.But Pytorch lets us do that in one\n",
    "line of code.It provides a SGD class which works like the Basic_Optim class only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we combine all our steps and use Pytorch classes to create our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4932 0.8179 0.8496 0.9141 0.9346 0.9482 0.957 0.9619 0.9658 0.9673 0.9692 0.9712 0.9741 0.9751 0.9761 0.9775 0.9775 0.978 0.9785 0.979 "
     ]
    }
   ],
   "source": [
    "#Pytorch has a SGD class for creating an optimizer by passing the model parameters and learning rate\n",
    "linear_model = nn.Linear(28*28,1)\n",
    "opt = SGD(linear_model.parameters(), lr)\n",
    "train_model(linear_model, 20)#training the model for 20 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell we used train_model function to calculate and print the accuracy for each epoch.We\n",
    "also use a for loop to iterate over each epoch.But fastai provides Learner.fit method which can be \n",
    "used in place of train_model and it allows us to pass the number of epochs and prints the accuracy.\n",
    "In the previous lessons also we had created cnn_learner and unet for Image classifier and image \n",
    "segmentation repsectively.We need to pass data in the form of dataloaders for the same.So we create\n",
    "dataloaders for our data by passing dl and valid_dl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fast.ai and pytorch also provide a method to create learner without using train_model by passing all the parameters required\n",
    "dls = DataLoaders(dl, valid_dl)#Creating data loader which dividesd data into batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we would be creating a simple learner without any application such as \"cnn_learner\" or \n",
    "\"unet_learner\".Also while creating Learner we pass all the elements we talked about in this Chapter\n",
    "such as the linear model,the optimizer,the loss function and the metrics along with the most important\n",
    "data loaders.So let's define our Learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the learner by passing the dataloader,the nn.Linear which initializes weights and bias and \n",
    "#calculates the predictions,the optimizer function such as SGD,the loss function used and metrics used\n",
    "learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,                                    #(Accuracy or squared loss)\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we call the fit method by passing the no of epochs and the learning rate(lr).This will train our\n",
    "epochs and also print the training and validation loss along with the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.636709</td>\n",
       "      <td>0.503144</td>\n",
       "      <td>0.495584</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.429828</td>\n",
       "      <td>0.248517</td>\n",
       "      <td>0.777233</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.161680</td>\n",
       "      <td>0.155361</td>\n",
       "      <td>0.861629</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.072948</td>\n",
       "      <td>0.097722</td>\n",
       "      <td>0.917566</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.040128</td>\n",
       "      <td>0.073205</td>\n",
       "      <td>0.936212</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027210</td>\n",
       "      <td>0.059466</td>\n",
       "      <td>0.950442</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021837</td>\n",
       "      <td>0.050799</td>\n",
       "      <td>0.957802</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019398</td>\n",
       "      <td>0.044980</td>\n",
       "      <td>0.964181</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.018122</td>\n",
       "      <td>0.040853</td>\n",
       "      <td>0.966143</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017330</td>\n",
       "      <td>0.037788</td>\n",
       "      <td>0.968106</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Pytorch also provides a fit method which can fit the learner with no of epochs and learning rate\n",
    "learn.fit(10, lr=lr)#It does it very fast and saves the time\n",
    "#This is a linear function but we ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that accuracy increases with each epoch which is a very good thing for any model.Previously\n",
    "we had trained this same model using different functions which had long lines of code but using \n",
    "Pytorch or fastai classes let us do all these things within a few lines of code.It is no magic just \n",
    "some packages for our use.We achieved around 96.8% accuracy with the linear model.Let's add some non\n",
    "linear to make it a neural network.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a Nonlinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried out building a simple linear classifier.We can add non-linearity to it to make it a network.\n",
    "We add a non linear function  between two linear classifiers to give neural network.We would first \n",
    "understand the basic structure of a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turning the linear function into Non-Linear neural network\n",
    "#@ stands for matrix multiplication\n",
    "def simple_net(xb): \n",
    "    res = xb@w1 + b1 #Linear function\n",
    "    res = res.max(tensor(0.0))#Does a max between the linear value and zero and turns negatives into 0\n",
    "    #It is called rectified linear unit function \n",
    "    res = res@w2 + b2#It will again turn it into a linear function\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above definition of a neural net has two linear classifiers with a max function.We initialize the\n",
    "parameters using the init_params.For understanding purpose we are using our defined functions here.\n",
    "Further we would be using the Pytorch functions and classes in the Chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight and Bias tensors\n",
    "w1 = init_params((28*28,30)) \n",
    "b1 = init_params(30)\n",
    "w2 = init_params((30,1))\n",
    "b2 = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here w1,w2 and b1,b2 are weights and bias tensors for the two linear classifiers.These are randomly \n",
    "initialized.W1 has 30 output activations which are then input to w2 so it has 30 input activations.The\n",
    "shape of the parameters can be changed to anything here.\n",
    "In the \"simple_net\" function the res.max(tensor(0.0)) is called \"the rectified linear unit\".It is also\n",
    "called \"ReLu\".The name of this function seems complex due to the word \"rectified\" but in real it's a \n",
    "very simple function.It actually makes all the negative nos zero and number greater than 0 increase\n",
    "linearly that's why it is called \"rectified linear unit\" or ReLu in short form.In pytorch we can \n",
    "access this function using F.relu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Rectified Linear unit function\n",
    "plot_function(F.relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When making neural networks more complex we mean that adding more layers to the neural net leads to\n",
    "more computation and modelling complex mathematical functions.But if we keep adding multiple layers \n",
    "one after other,it results in multiplying different things and adding them up which is equivalent to\n",
    "to multiplying things and then adding them just once.In terms of layers it means instead of multiple\n",
    "layers we can have single layer with different sets of parameters.\n",
    "Non linearity is added to make the neural net more generalized.Also it has been proven that such \n",
    "functions can actually solve any problem in the world ,we just need right set of parameters w1 and w2.\n",
    "This theorem is actually called \"universal approximation theorem\".Below we will create a neural net \n",
    "with three layers, 2 linear(nn.Linear) and one non-linear(nn.ReLU).We should note here that we will be\n",
    "using Pytorch classes to create this neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting a sequential linear layers and hidden layer for nonlinearity using Pytorch's nn.Sequential class\n",
    "#it passes the results of one function to other\n",
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,30), #Linear (output has 30 actiovations)\n",
    "    nn.ReLU(),#Non Linear RElu\n",
    "    nn.Linear(30,1)#Linear(input has 30 activations)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create the learner in the same way we had created before.We also pass the dataloaders,the \n",
    "neural_net,the optimizer,the loss function and the metrics through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training a learner for dataloaders using simple learner \n",
    "learn = Learner(dls, simple_net, opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use Pytorch's \"learn.fit\" method to train our model for 40 epochs and learning rate of 0.1.We\n",
    "pass these as the arguments to the method.Since this model contains multiple layers so it is a deeper \n",
    "model so we use more number of epochs and a less learning rate to train the learner.\n",
    "\n",
    "Previously when we had introduced ReLU we had used \"F.relu\" to plot the function.Now when we defined\n",
    "our neural net in the non linear layer we used nn.ReLU.In Pytorch some functions also have same forms \n",
    "in modules.They can be accessed by replacing F by nn.When we define neural net nn.Sequential uses \n",
    "module form of the layers therefore we use nn.ReLU and these are classes so we instantiate them by\n",
    "nn.ReLU()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.333021</td>\n",
       "      <td>0.396112</td>\n",
       "      <td>0.512267</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.152461</td>\n",
       "      <td>0.235238</td>\n",
       "      <td>0.797350</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.083573</td>\n",
       "      <td>0.117471</td>\n",
       "      <td>0.911678</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.054309</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.940628</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.040829</td>\n",
       "      <td>0.061228</td>\n",
       "      <td>0.956330</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034006</td>\n",
       "      <td>0.051490</td>\n",
       "      <td>0.963690</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030123</td>\n",
       "      <td>0.045381</td>\n",
       "      <td>0.966634</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.027619</td>\n",
       "      <td>0.041218</td>\n",
       "      <td>0.968106</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.025825</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.969087</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.024441</td>\n",
       "      <td>0.035901</td>\n",
       "      <td>0.969578</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023321</td>\n",
       "      <td>0.034082</td>\n",
       "      <td>0.971541</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.022387</td>\n",
       "      <td>0.032598</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.021592</td>\n",
       "      <td>0.031353</td>\n",
       "      <td>0.974485</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.020904</td>\n",
       "      <td>0.030284</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.029352</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.019766</td>\n",
       "      <td>0.028526</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.019288</td>\n",
       "      <td>0.027788</td>\n",
       "      <td>0.976448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.018857</td>\n",
       "      <td>0.027124</td>\n",
       "      <td>0.977429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.018465</td>\n",
       "      <td>0.026523</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.018107</td>\n",
       "      <td>0.025977</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.017777</td>\n",
       "      <td>0.025479</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.017473</td>\n",
       "      <td>0.025022</td>\n",
       "      <td>0.979392</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.017191</td>\n",
       "      <td>0.024601</td>\n",
       "      <td>0.980373</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.016927</td>\n",
       "      <td>0.024213</td>\n",
       "      <td>0.980373</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.016680</td>\n",
       "      <td>0.023855</td>\n",
       "      <td>0.981354</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.016449</td>\n",
       "      <td>0.023521</td>\n",
       "      <td>0.981354</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.016230</td>\n",
       "      <td>0.023211</td>\n",
       "      <td>0.981354</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.016023</td>\n",
       "      <td>0.022922</td>\n",
       "      <td>0.981354</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.015827</td>\n",
       "      <td>0.022653</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.015641</td>\n",
       "      <td>0.022401</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.015463</td>\n",
       "      <td>0.022165</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.015294</td>\n",
       "      <td>0.021944</td>\n",
       "      <td>0.983317</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.015132</td>\n",
       "      <td>0.021736</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.014977</td>\n",
       "      <td>0.021541</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.014828</td>\n",
       "      <td>0.021357</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.014686</td>\n",
       "      <td>0.021184</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.014549</td>\n",
       "      <td>0.021019</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.014417</td>\n",
       "      <td>0.020864</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.020716</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.014168</td>\n",
       "      <td>0.020576</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Training ur model for 40 epochs with linear rate 0.1\n",
    "learn.fit(40, lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So increase in the number of epochs results in increase in our accuracy of the model.Fastai also\n",
    "gives us functionality to see the accuracy pattern with the training process.The values are stored in\n",
    "learn.recorder and therefore we can plot accuracy with \"the number of epochs\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#L class has itemgot which takes 2nd item for every row and here we can see that it plots accuracy vs\n",
    "#the no of epochs\n",
    "plt.plot(L(learn.recorder.values).itemgot(2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also print the final accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98233562707901"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recorder.values gives the table of metrics for each epoch\n",
    "#Displaying the accuracy for final epoch\n",
    "learn.recorder.values[-1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually save the architecture of the model using the model method.It will store the number and\n",
    "the types of layers present in the net.We can also get parameters for each layer using .parameters()\n",
    "method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 0.0221,  0.0056,  0.0311,  ..., -0.0346,  0.0339, -0.0108],\n",
       "         [ 0.0173,  0.0260,  0.0042,  ..., -0.0003, -0.0031,  0.0192],\n",
       "         [-0.0169, -0.0154, -0.0292,  ..., -0.0234,  0.0339, -0.0021],\n",
       "         ...,\n",
       "         [ 0.0080, -0.0167, -0.0217,  ..., -0.0069,  0.0005,  0.0041],\n",
       "         [-0.0155, -0.0012, -0.0065,  ...,  0.0157, -0.0036,  0.0091],\n",
       "         [ 0.0194,  0.0271,  0.0235,  ..., -0.0133,  0.0217,  0.0088]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0010, -0.0151, -0.0222, -0.0243,  0.1202, -0.0458, -0.0117, -0.0033,  0.0362, -0.0414, -0.0424, -0.0313, -0.0168, -0.0165, -0.0413,  0.0941, -0.0371, -0.0510, -0.0029,  0.1855, -0.0610,\n",
       "          0.0396,  0.1468,  0.0117,  0.1596, -0.0124, -0.0010, -0.0137,  0.0011, -0.0017], requires_grad=True))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=learn.model #gives the sequences of the layers in model\n",
    "w,b=m[0].parameters() #gives the parameters of the first linear layer\n",
    "w,b#Weights,bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already learnt this before that when we pass images through different layers in neural net.Each\n",
    "layer is responsible for extracting different features.We can actually display the image through \n",
    "different layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the middle of this Chapter we learnt about \"Universal Approximation Theorem\" which says that Deep\n",
    "learning can actually solve any complex problem in this world.We can solve much more complex problems\n",
    "later on.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going Deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MNIST dataset we built a neural network of 2 layers with one layer of non-linearity in between.\n",
    "But as the model becomes more deep(more layers),choosing right set of weights become difficult.\n",
    "A model with two linear layers with a nonlinear layer between them is enough for approximating any\n",
    "complex mathematical function.But to get a better performance we would need more deeper models.More \n",
    "deeper models mean more layers but not necessarily more parameters we can have smaller matrices of \n",
    "parameters with more number of layers and we could get better performance than that of more parameters\n",
    "and less layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are more layers but less parameters,it also becomes easy to train the model quickly and with\n",
    "less memory.Earlier researchers mostly focused on solving problems through linear layers rather than\n",
    "non-linear layer.Later some experiments showed that deep models could perform better.Let'see change\n",
    "in model performance when we train it using a 18 layer pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Long but got scalar type Int for argument #2 'target' in call to _thnn_nll_loss_forward",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-788b3d5f51b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m learn = cnn_learner(dls, resnet18,\n\u001b[0;32m      3\u001b[0m                     loss_func=F.cross_entropy, metrics=accuracy)\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastcore\\logargs.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0minit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'init_args'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0minst\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mto_return\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\callback\\schedule.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[1;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)\u001b[0m\n\u001b[0;32m    111\u001b[0m     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n\u001b[0;32m    112\u001b[0m               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mParamScheduler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscheds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;31m# Cell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastcore\\logargs.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0minit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'init_args'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0minst\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mto_return\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'before_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;33m;\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_cancel_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m        \u001b[1;33m;\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'epoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mlog_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbut\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cbs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'before_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;33m;\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_cancel_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m        \u001b[1;33m;\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'before_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;33m;\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_cancel_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m        \u001b[1;33m;\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[1;34m(self, i, b)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'batch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'before_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;33m;\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_cancel_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m        \u001b[1;33m;\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'after_pred'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'after_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2420\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2421\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2422\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2216\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[0;32m   2217\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2218\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2219\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2220\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Int for argument #2 'target' in call to _thnn_nll_loss_forward"
     ]
    }
   ],
   "source": [
    "dls = ImageDataLoaders.from_folder(path,num_workers=0)\n",
    "learn = cnn_learner(dls, resnet18,\n",
    "                    loss_func=F.cross_entropy, metrics=accuracy)\n",
    "learn.fit_one_cycle(1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jargon Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How is a grayscale image represented on a computer? How about a color image?\n",
    "1. How are the files and folders in the `MNIST_SAMPLE` dataset structured? Why?\n",
    "1. Explain how the \"pixel similarity\" approach to classifying digits works.\n",
    "1. What is a list comprehension? Create one now that selects odd numbers from a list and doubles them.\n",
    "1. What is a \"rank-3 tensor\"?\n",
    "1. What is the difference between tensor rank and shape? How do you get the rank from the shape?\n",
    "1. What are RMSE and L1 norm?\n",
    "1. How can you apply a calculation on thousands of numbers at once, many thousands of times faster than a Python loop?\n",
    "1. Create a 33 tensor or array containing the numbers from 1 to 9. Double it. Select the bottom-right four numbers.\n",
    "1. What is broadcasting?\n",
    "1. Are metrics generally calculated using the training set, or the validation set? Why?\n",
    "1. What is SGD?\n",
    "1. Why does SGD use mini-batches?\n",
    "1. What are the seven steps in SGD for machine learning?\n",
    "1. How do we initialize the weights in a model?\n",
    "1. What is \"loss\"?\n",
    "1. Why can't we always use a high learning rate?\n",
    "1. What is a \"gradient\"?\n",
    "1. Do you need to know how to calculate gradients yourself?\n",
    "1. Why can't we use accuracy as a loss function?\n",
    "1. Draw the sigmoid function. What is special about its shape?\n",
    "1. What is the difference between a loss function and a metric?\n",
    "1. What is the function to calculate new weights using a learning rate?\n",
    "1. What does the `DataLoader` class do?\n",
    "1. Write pseudocode showing the basic steps taken in each epoch for SGD.\n",
    "1. Create a function that, if passed two arguments `[1,2,3,4]` and `'abcd'`, returns `[(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')]`. What is special about that output data structure?\n",
    "1. What does `view` do in PyTorch?\n",
    "1. What are the \"bias\" parameters in a neural network? Why do we need them?\n",
    "1. What does the `@` operator do in Python?\n",
    "1. What does the `backward` method do?\n",
    "1. Why do we have to zero the gradients?\n",
    "1. What information do we have to pass to `Learner`?\n",
    "1. Show Python or pseudocode for the basic steps of a training loop.\n",
    "1. What is \"ReLU\"? Draw a plot of it for values from `-2` to `+2`.\n",
    "1. What is an \"activation function\"?\n",
    "1. What's the difference between `F.relu` and `nn.ReLU`?\n",
    "1. The universal approximation theorem shows that any function can be approximated as closely as needed using just one nonlinearity. So why do we normally use more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans-1.A gray-scale image is represented as 2D matrices with rows and columns containing pixel values \n",
    "between 0 and 255.Color images contain an extra dimension for color coding and thus they can be repre\n",
    "sented as 3D matrices.\n",
    "Ans-2.MNIST_DATASET contain two main folders called \"train\" and \"valid\" which contain training and \n",
    "validation set respectively.Further these folders contain folders 3 and 7 containing images of 3 and\n",
    "7 respectively.\n",
    "Ans-3.The pixel similarity approach basically calculates the mean of the pixel values for each \n",
    "pixel across all images differently for 3 and 7.In this way we get a baseline ideal image for both 3 \n",
    "and 7 containing mean pixel values which are then compared with test images and error is calculated.\n",
    "On the basis of min error it is decided if it is 3 or 7.\n",
    "Ans-4.List comprehension is an easy and fast way to create lists from existing lists.\n",
    "Eg.odd_list=[2*l for l in list_1 if l%2!=0]\n",
    "Ans-5 Rank 3 tensor is a tensor with 3 dimensions.It is made up of 3D matrices or arrays.It is also\n",
    "called triad.\n",
    "Ans-6 Rank of a tensor is simply the number of dimensions of tensor whereas shape gives the length of\n",
    "each dimension or axis of the tensor.We can get the rank of a tensor using the number of elements in \n",
    "its shape.\n",
    "Ans-7 RMSE stands for root mean squared error.It is one of the loss functions used for optimizing the\n",
    "parameters.It is the square root of mean of the squared values of the difference between the targets \n",
    "and predictions.L1 Norm is the mean absolute error.It is simply the mean of the absolute difference\n",
    "between the targets and the predictions.\n",
    "Ans-8 It can be done using an array functionality called Broadcasting where operations are performed\n",
    "between arrays or tensors of different shapes.It extends the tensor with lower rank so that it is same\n",
    "as the one with the higher rank and then operations can be done on individual elements.\n",
    "Ans-9 arr=tensor(range(1,9))\n",
    "      arr=arr.view(3,3)\n",
    "      arr=arr*2\n",
    "Ans-10  Broadcasting is used for performing operations between tensors/arrays of different ranks.It\n",
    "expands the rank of the tensor with lower rank.\n",
    "Ans-11 Metrics are calculated mostly for validation set but so as to evaluate model's full performance\n",
    "and so as to improve the model training and validation metrics both are considered.\n",
    "Ans-12 SGD stands for Stochastic Gradient Descent.It is one of the methods used for optimizing the \n",
    "parameters in neural networks.It uses mini batches of data to update the weights.\n",
    "Ans-13 SGD uses mini batches of data.It is because if it uses whole dataset for training,it would take\n",
    "a lot of time and using a single item wouldn't produce much information.Therefore subsets of data\n",
    "called mini-batches are used.\n",
    "Ans-14 The seven steps of SGD are as follows:-\n",
    "1.Randomly Initialize set of weights.\n",
    "2.Using them predict for each Image if it is 3 or 7.\n",
    "3.Calculate loss on the basis of predictions.Use appropriate Loss function.\n",
    "4.Now calculate gradient which will show how the weights should change.\n",
    "5.Update the weights according to gradient.\n",
    "6.Again make predictions and repeat the process\n",
    "7.Continue doing the same till you find that your model is making correct predictions.\n",
    "Ans-15 Weights are initialized randomly by passing the shape of the input matrix or sometimes in case \n",
    "of Transfer Learning,it uses weights of the pre-trained model.\n",
    "Ans-16 Loss is a measure of the difference between the target values and the predicted values.\n",
    "Ans-17 A high learning rate would result in overstepping of the parameters and instead of reaching the\n",
    "minima the values can shoot up and it can reach beyond minima.\n",
    "Ans-18 A \"gradient\" is simply the change in the dependent variable divided by the change in the \n",
    "independent variable.\n",
    "Ans-19 We should know the meaning of the gradient rest Pytorch provides special AutoGrad Package for \n",
    "directly calculating the gradient.\n",
    "Ans-20 Accuracy is a metric for evaluating model's performanc.Accuracy changes only when there is a\n",
    "change in any incorrect prediction or some change in weights.A small change in weights won't change \n",
    "accuracy much and therefor gradient would be very less nearly 0.For loss function, we need something\n",
    "to have a significant gradient value so that we can update the weights value.If the gradient is 0,then\n",
    "Accuracy cannot be used as a loss function.\n",
    "Ans-21 Sigmoid function is special because it has a universal range of (0,1).It maps all the real \n",
    "values between 0 and 1 which is then used as activation functions sometimes and a threshold is decided\n",
    "to separate between the classes in predictions.\n",
    "Ans-22 A loss function is used for automating the gradient calculation.Our weights are updated on the \n",
    "basis of gradient values.Set of weights are optimized to reach minima of the loss function which is a\n",
    "measure of the distance between target and predictions.\n",
    "Ans-23 W-=lr*gradient(w)\n",
    "Ans-24 DataLoader class divides the data into mini batches of a definite batch size so that data is \n",
    "fed into the model in batches.\n",
    "Ans-26 It is called Dataset and when a list of indepenent and dependent variables are passed,it maps\n",
    "both into single tuples and returns a list of tuples containing independent and dependent variable \n",
    "values.\n",
    "Ans-27 .view method changes the shape of any tensor in Pytorch.\n",
    "Ans-28 \"Bias\" is a value added to the matrix multiplication product of weights and the input image.\n",
    "Sometimes when the input image is a sparse matrix then if they are multiplied by weights,the product\n",
    "is zero.Therefore we won't get any gradients.Adding a bias term ensures that the prediction is always\n",
    "non zero.\n",
    "Ans-29 @ operator stands for Matrix Multiplication in Pytorch\n",
    "Ans-30 Backward method calculates gradient for the particular matrox whenever any operation is \n",
    "Ans-31 We do \"opt.grad_zero\" to clear the gradients previously calculated as they keep up adding every\n",
    "time each operation is performed.\n",
    "Ans-32 In learner we need to pass the dataloaders,the model,the optimizer,the loss function and the \n",
    "metrics.\n",
    "Ans-33 def train_model(model,epochs)\n",
    "       for i in range(epochs)\n",
    "       train_epoch(model)\n",
    "       validate_epoch(model)\n",
    "Ans-34 ReLu stands for rectified linear unit.It is also one of the activation functions and generally\n",
    "used for introducing Non-Linearity to the model.\n",
    "Ans-35 layers in a neural network can be linear or non-linear.To introduce non-linearity,the output \n",
    "from a layer should be mapped with a non-linear function and such functions are called non-linear \n",
    "functions.As they help in activating the neuron.\n",
    "Anns-36 Pytorch provides functions both in the form of classes as well as pure functions.Pytorch's \n",
    "nn.module has nn.ReLu class and functions module has F.ReLU.Both are same activations only.It's just \n",
    "that while using in neural networks,we prefer to use them as nn.ReLU objects.\n",
    "Ans-37 To improve the accuracy and performance we tend to use more non-linear layers in a neural \n",
    "network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create your own implementation of `Learner` from scratch, based on the training loop shown in this chapter.\n",
    "1. Complete all the steps in this chapter using the full MNIST datasets (that is, for all digits, not just 3s and 7s). This is a significant project and will take you quite a bit of time to complete! You'll need to do some of your own research to figure out how to overcome some obstacles you'll meet on the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
